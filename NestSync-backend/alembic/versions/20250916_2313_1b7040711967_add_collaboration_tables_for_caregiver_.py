"""Add collaboration tables for caregiver collaboration system

Revision ID: 1b7040711967
Revises: 0b11c7441f2f
Create Date: 2025-09-16 23:13:30.712897-04:00

PIPEDA Compliance: This migration handles personal data according to Canadian privacy laws.
Data Residency: All data operations occur within Canadian data centers.
"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '1b7040711967'
down_revision = '0b11c7441f2f'
branch_labels = None
depends_on = None


def upgrade() -> None:
    """
    Apply migration changes
    
    PIPEDA Compliance Notes:
    - All personal data fields are properly encrypted/protected
    - Audit trails are maintained for all data changes
    - Data retention policies are enforced
    - Canadian timezone (America/Toronto) is used for all timestamps
    """
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('families',
    sa.Column('name', sa.String(length=255), nullable=False, comment='Family name'),
    sa.Column('family_type', sa.Enum('PERSONAL', 'STANDARD', 'INSTITUTIONAL', name='familytype'), nullable=False, comment='Type of family (personal/standard/institutional)'),
    sa.Column('description', sa.Text(), nullable=True, comment='Family description'),
    sa.Column('created_by', sa.UUID(), nullable=False, comment='User who created the family'),
    sa.Column('settings', sa.JSON(), nullable=False, comment='Family settings and preferences'),
    sa.Column('id', sa.UUID(), nullable=False, comment='Unique identifier'),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False, comment='Record creation timestamp (UTC)'),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=False, comment='Record last update timestamp (UTC)'),
    sa.Column('deleted_at', sa.DateTime(timezone=True), nullable=True, comment='Soft delete timestamp (PIPEDA compliance)'),
    sa.Column('is_deleted', sa.Boolean(), nullable=False, comment='Soft delete flag'),
    sa.Column('updated_by', sa.UUID(), nullable=True, comment='User who last updated this record'),
    sa.Column('deleted_by', sa.UUID(), nullable=True, comment='User who deleted this record'),
    sa.ForeignKeyConstraint(['created_by'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('families', schema=None) as batch_op:
        batch_op.create_index('idx_families_created_by', ['created_by'], unique=False)
        batch_op.create_index('idx_families_type', ['family_type'], unique=False)

    op.create_table('caregiver_invitations',
    sa.Column('family_id', sa.UUID(), nullable=False, comment='Family ID'),
    sa.Column('email', sa.String(length=255), nullable=False, comment='Email address of invited caregiver'),
    sa.Column('role', sa.Enum('FAMILY_CORE', 'EXTENDED_FAMILY', 'PROFESSIONAL', 'INSTITUTIONAL', name='memberrole'), nullable=False, comment='Proposed role for invitee'),
    sa.Column('invitation_token', sa.String(length=255), nullable=False, comment='Secure invitation token'),
    sa.Column('invited_by', sa.UUID(), nullable=False, comment='User who sent invitation'),
    sa.Column('expires_at', sa.DateTime(timezone=True), nullable=False, comment='When invitation expires'),
    sa.Column('accepted_at', sa.DateTime(timezone=True), nullable=True, comment='When invitation was accepted'),
    sa.Column('accepted_by', sa.UUID(), nullable=True, comment='User who accepted invitation'),
    sa.Column('status', sa.Enum('PENDING', 'ACCEPTED', 'EXPIRED', 'REVOKED', name='invitationstatus'), nullable=False, comment='Invitation status'),
    sa.Column('access_restrictions', sa.JSON(), nullable=False, comment='Specific access restrictions for invitation'),
    sa.Column('id', sa.UUID(), nullable=False, comment='Unique identifier'),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False, comment='Record creation timestamp (UTC)'),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=False, comment='Record last update timestamp (UTC)'),
    sa.Column('deleted_at', sa.DateTime(timezone=True), nullable=True, comment='Soft delete timestamp (PIPEDA compliance)'),
    sa.Column('is_deleted', sa.Boolean(), nullable=False, comment='Soft delete flag'),
    sa.Column('created_by', sa.UUID(), nullable=True, comment='User who created this record'),
    sa.Column('updated_by', sa.UUID(), nullable=True, comment='User who last updated this record'),
    sa.Column('deleted_by', sa.UUID(), nullable=True, comment='User who deleted this record'),
    sa.ForeignKeyConstraint(['accepted_by'], ['users.id'], ),
    sa.ForeignKeyConstraint(['family_id'], ['families.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['invited_by'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('invitation_token')
    )
    with op.batch_alter_table('caregiver_invitations', schema=None) as batch_op:
        batch_op.create_index('idx_invitations_email', ['email'], unique=False)
        batch_op.create_index('idx_invitations_family', ['family_id'], unique=False)
        batch_op.create_index('idx_invitations_status', ['status'], unique=False)
        batch_op.create_index('idx_invitations_token', ['invitation_token'], unique=False)

    op.create_table('collaboration_logs',
    sa.Column('family_id', sa.UUID(), nullable=False, comment='Family ID'),
    sa.Column('actor_user_id', sa.UUID(), nullable=True, comment='User who performed the action'),
    sa.Column('action_type', sa.Enum('FAMILY_CREATED', 'MEMBER_INVITED', 'MEMBER_JOINED', 'MEMBER_REMOVED', 'ROLE_CHANGED', 'CHILD_ADDED', 'CHILD_REMOVED', 'ACTIVITY_LOGGED', 'PROFILE_UPDATED', 'SETTINGS_CHANGED', 'DATA_ACCESSED', 'DATA_EXPORTED', name='logaction'), nullable=False, comment='Type of action performed'),
    sa.Column('target_type', sa.String(length=50), nullable=True, comment='Type of target object (child, member, etc.)'),
    sa.Column('target_id', sa.UUID(), nullable=True, comment='ID of target object'),
    sa.Column('details', sa.JSON(), nullable=False, comment='Action details and metadata'),
    sa.Column('ip_address', postgresql.INET(), nullable=True, comment='IP address of request'),
    sa.Column('user_agent', sa.Text(), nullable=True, comment='User agent string'),
    sa.Column('id', sa.UUID(), nullable=False, comment='Unique identifier'),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False, comment='Record creation timestamp (UTC)'),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=False, comment='Record last update timestamp (UTC)'),
    sa.Column('deleted_at', sa.DateTime(timezone=True), nullable=True, comment='Soft delete timestamp (PIPEDA compliance)'),
    sa.Column('is_deleted', sa.Boolean(), nullable=False, comment='Soft delete flag'),
    sa.Column('created_by', sa.UUID(), nullable=True, comment='User who created this record'),
    sa.Column('updated_by', sa.UUID(), nullable=True, comment='User who last updated this record'),
    sa.Column('deleted_by', sa.UUID(), nullable=True, comment='User who deleted this record'),
    sa.ForeignKeyConstraint(['actor_user_id'], ['users.id'], ),
    sa.ForeignKeyConstraint(['family_id'], ['families.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('collaboration_logs', schema=None) as batch_op:
        batch_op.create_index('idx_logs_action', ['action_type'], unique=False)
        batch_op.create_index('idx_logs_actor', ['actor_user_id'], unique=False)
        batch_op.create_index('idx_logs_created', ['created_at'], unique=False)
        batch_op.create_index('idx_logs_family', ['family_id'], unique=False)

    op.create_table('family_members',
    sa.Column('user_id', sa.UUID(), nullable=False, comment='User ID'),
    sa.Column('family_id', sa.UUID(), nullable=False, comment='Family ID'),
    sa.Column('role', sa.Enum('FAMILY_CORE', 'EXTENDED_FAMILY', 'PROFESSIONAL', 'INSTITUTIONAL', name='memberrole'), nullable=False, comment='Member role in family'),
    sa.Column('permissions', sa.JSON(), nullable=False, comment='Specific permissions for this member'),
    sa.Column('joined_at', sa.DateTime(timezone=True), nullable=False, comment='When member joined family'),
    sa.Column('access_expires_at', sa.DateTime(timezone=True), nullable=True, comment='When member access expires (for temporary access)'),
    sa.Column('invited_by', sa.UUID(), nullable=True, comment='User who invited this member'),
    sa.Column('status', sa.Enum('ACTIVE', 'INACTIVE', 'SUSPENDED', 'EXPIRED', name='memberstatus'), nullable=False, comment='Member status'),
    sa.Column('id', sa.UUID(), nullable=False, comment='Unique identifier'),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False, comment='Record creation timestamp (UTC)'),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=False, comment='Record last update timestamp (UTC)'),
    sa.Column('deleted_at', sa.DateTime(timezone=True), nullable=True, comment='Soft delete timestamp (PIPEDA compliance)'),
    sa.Column('is_deleted', sa.Boolean(), nullable=False, comment='Soft delete flag'),
    sa.Column('created_by', sa.UUID(), nullable=True, comment='User who created this record'),
    sa.Column('updated_by', sa.UUID(), nullable=True, comment='User who last updated this record'),
    sa.Column('deleted_by', sa.UUID(), nullable=True, comment='User who deleted this record'),
    sa.ForeignKeyConstraint(['family_id'], ['families.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['invited_by'], ['users.id'], ),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('user_id', 'family_id', name='uq_family_member')
    )
    with op.batch_alter_table('family_members', schema=None) as batch_op:
        batch_op.create_index('idx_family_members_family', ['family_id'], unique=False)
        batch_op.create_index('idx_family_members_role', ['role'], unique=False)
        batch_op.create_index('idx_family_members_status', ['status'], unique=False)
        batch_op.create_index('idx_family_members_user', ['user_id'], unique=False)

    op.create_table('activities',
    sa.Column('child_id', sa.UUID(), nullable=False, comment='Child this activity is for'),
    sa.Column('activity_type', sa.String(length=50), nullable=False, comment='Type of activity (diaper_change, feeding, etc.)'),
    sa.Column('logged_at', sa.DateTime(timezone=True), nullable=False, comment='When the activity occurred'),
    sa.Column('duration_minutes', sa.Integer(), nullable=True, comment='Duration of activity in minutes (for feeding, sleep, etc.)'),
    sa.Column('notes', sa.Text(), nullable=True, comment='Additional notes about the activity'),
    sa.Column('activity_metadata', sa.JSON(), nullable=False, comment='Activity-specific metadata (diaper type, feeding amount, etc.)'),
    sa.Column('logged_by_user_id', sa.UUID(), nullable=True, comment='User who logged this activity'),
    sa.Column('family_context', sa.JSON(), nullable=False, comment='Family collaboration context'),
    sa.Column('collaboration_metadata', sa.JSON(), nullable=False, comment='Collaboration-specific metadata (conflicts, attributions, etc.)'),
    sa.Column('parent_id', sa.UUID(), nullable=True, comment='Legacy parent ID (deprecated - use logged_by_user_id)'),
    sa.Column('id', sa.UUID(), nullable=False, comment='Unique identifier'),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False, comment='Record creation timestamp (UTC)'),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=False, comment='Record last update timestamp (UTC)'),
    sa.Column('deleted_at', sa.DateTime(timezone=True), nullable=True, comment='Soft delete timestamp (PIPEDA compliance)'),
    sa.Column('is_deleted', sa.Boolean(), nullable=False, comment='Soft delete flag'),
    sa.Column('created_by', sa.UUID(), nullable=True, comment='User who created this record'),
    sa.Column('updated_by', sa.UUID(), nullable=True, comment='User who last updated this record'),
    sa.Column('deleted_by', sa.UUID(), nullable=True, comment='User who deleted this record'),
    sa.ForeignKeyConstraint(['child_id'], ['children.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['logged_by_user_id'], ['users.id'], ),
    sa.ForeignKeyConstraint(['parent_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    with op.batch_alter_table('activities', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_activities_activity_type'), ['activity_type'], unique=False)
        batch_op.create_index(batch_op.f('ix_activities_child_id'), ['child_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_activities_logged_at'), ['logged_at'], unique=False)
        batch_op.create_index(batch_op.f('ix_activities_logged_by_user_id'), ['logged_by_user_id'], unique=False)

    op.create_table('caregiver_presence',
    sa.Column('user_id', sa.UUID(), nullable=False, comment='User ID'),
    sa.Column('family_id', sa.UUID(), nullable=False, comment='Family ID'),
    sa.Column('child_id', sa.UUID(), nullable=True, comment='Currently caring for child (optional)'),
    sa.Column('status', sa.Enum('ONLINE', 'AWAY', 'CARING', 'OFFLINE', name='presencestatus'), nullable=False, comment='Current presence status'),
    sa.Column('current_activity', sa.String(length=100), nullable=True, comment='Description of current activity'),
    sa.Column('last_seen', sa.DateTime(timezone=True), nullable=False, comment='Last activity timestamp'),
    sa.Column('session_id', sa.String(length=255), nullable=True, comment='Session identifier for presence tracking'),
    sa.Column('device_info', sa.JSON(), nullable=False, comment='Device information for presence context'),
    sa.Column('id', sa.UUID(), nullable=False, comment='Unique identifier'),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False, comment='Record creation timestamp (UTC)'),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=False, comment='Record last update timestamp (UTC)'),
    sa.Column('deleted_at', sa.DateTime(timezone=True), nullable=True, comment='Soft delete timestamp (PIPEDA compliance)'),
    sa.Column('is_deleted', sa.Boolean(), nullable=False, comment='Soft delete flag'),
    sa.Column('created_by', sa.UUID(), nullable=True, comment='User who created this record'),
    sa.Column('updated_by', sa.UUID(), nullable=True, comment='User who last updated this record'),
    sa.Column('deleted_by', sa.UUID(), nullable=True, comment='User who deleted this record'),
    sa.ForeignKeyConstraint(['child_id'], ['children.id'], ),
    sa.ForeignKeyConstraint(['family_id'], ['families.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('user_id', 'family_id', name='uq_caregiver_presence')
    )
    with op.batch_alter_table('caregiver_presence', schema=None) as batch_op:
        batch_op.create_index('idx_presence_child', ['child_id'], unique=False)
        batch_op.create_index('idx_presence_family', ['family_id'], unique=False)
        batch_op.create_index('idx_presence_last_seen', ['last_seen'], unique=False)
        batch_op.create_index('idx_presence_status', ['status'], unique=False)

    op.create_table('family_child_access',
    sa.Column('family_id', sa.UUID(), nullable=False, comment='Family ID'),
    sa.Column('child_id', sa.UUID(), nullable=False, comment='Child ID'),
    sa.Column('access_level', sa.Enum('FULL', 'LIMITED', 'READ_ONLY', 'EMERGENCY_ONLY', name='accesslevel'), nullable=False, comment='Level of access to child data'),
    sa.Column('granted_at', sa.DateTime(timezone=True), nullable=False, comment='When access was granted'),
    sa.Column('granted_by', sa.UUID(), nullable=False, comment='User who granted access'),
    sa.Column('id', sa.UUID(), nullable=False, comment='Unique identifier'),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=False, comment='Record creation timestamp (UTC)'),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=False, comment='Record last update timestamp (UTC)'),
    sa.Column('deleted_at', sa.DateTime(timezone=True), nullable=True, comment='Soft delete timestamp (PIPEDA compliance)'),
    sa.Column('is_deleted', sa.Boolean(), nullable=False, comment='Soft delete flag'),
    sa.Column('created_by', sa.UUID(), nullable=True, comment='User who created this record'),
    sa.Column('updated_by', sa.UUID(), nullable=True, comment='User who last updated this record'),
    sa.Column('deleted_by', sa.UUID(), nullable=True, comment='User who deleted this record'),
    sa.ForeignKeyConstraint(['child_id'], ['children.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['family_id'], ['families.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['granted_by'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('family_id', 'child_id', name='uq_family_child_access')
    )
    with op.batch_alter_table('family_child_access', schema=None) as batch_op:
        batch_op.create_index('idx_family_child_child', ['child_id'], unique=False)
        batch_op.create_index('idx_family_child_family', ['family_id'], unique=False)

    op.drop_table('mfa_amr_claims', schema='auth')
    op.drop_table('schema_migrations', schema='realtime')
    op.drop_table('s3_multipart_uploads_parts', schema='storage')
    with op.batch_alter_table('identities', schema='auth') as batch_op:
        batch_op.drop_index('identities_email_idx', postgresql_ops={'email': 'text_pattern_ops'})
        batch_op.drop_index('identities_user_id_idx')

    op.drop_table('identities', schema='auth')
    with op.batch_alter_table('mfa_factors', schema='auth') as batch_op:
        batch_op.drop_index('factor_id_created_at_idx')
        batch_op.drop_index('mfa_factors_user_friendly_name_unique', postgresql_where="(TRIM(BOTH FROM friendly_name) <> ''::text)")
        batch_op.drop_index('mfa_factors_user_id_idx')
        batch_op.drop_index('unique_phone_factor_per_user')

    op.drop_table('mfa_factors', schema='auth')
    with op.batch_alter_table('users', schema='auth') as batch_op:
        batch_op.drop_index('confirmation_token_idx', postgresql_where="((confirmation_token)::text !~ '^[0-9 ]*$'::text)")
        batch_op.drop_index('email_change_token_current_idx', postgresql_where="((email_change_token_current)::text !~ '^[0-9 ]*$'::text)")
        batch_op.drop_index('email_change_token_new_idx', postgresql_where="((email_change_token_new)::text !~ '^[0-9 ]*$'::text)")
        batch_op.drop_index('reauthentication_token_idx', postgresql_where="((reauthentication_token)::text !~ '^[0-9 ]*$'::text)")
        batch_op.drop_index('recovery_token_idx', postgresql_where="((recovery_token)::text !~ '^[0-9 ]*$'::text)")
        batch_op.drop_index('users_email_partial_key', postgresql_where='(is_sso_user = false)')
        batch_op.drop_index('users_instance_id_email_idx')
        batch_op.drop_index('users_instance_id_idx')
        batch_op.drop_index('users_is_anonymous_idx')

    op.drop_table('users', schema='auth')
    op.drop_table('messages', schema='realtime')
    op.drop_table('schema_migrations', schema='auth')
    with op.batch_alter_table('saml_providers', schema='auth') as batch_op:
        batch_op.drop_index('saml_providers_sso_provider_id_idx')

    op.drop_table('saml_providers', schema='auth')
    with op.batch_alter_table('secrets', schema='vault') as batch_op:
        batch_op.drop_index('secrets_name_idx', postgresql_where='(name IS NOT NULL)')

    op.drop_table('secrets', schema='vault')
    with op.batch_alter_table('audit_log_entries', schema='auth') as batch_op:
        batch_op.drop_index('audit_logs_instance_id_idx')

    op.drop_table('audit_log_entries', schema='auth')
    with op.batch_alter_table('s3_multipart_uploads', schema='storage') as batch_op:
        batch_op.drop_index('idx_multipart_uploads_list')

    op.drop_table('s3_multipart_uploads', schema='storage')
    with op.batch_alter_table('saml_relay_states', schema='auth') as batch_op:
        batch_op.drop_index('saml_relay_states_created_at_idx')
        batch_op.drop_index('saml_relay_states_for_email_idx')
        batch_op.drop_index('saml_relay_states_sso_provider_id_idx')

    op.drop_table('saml_relay_states', schema='auth')
    with op.batch_alter_table('sso_domains', schema='auth') as batch_op:
        batch_op.drop_index('sso_domains_domain_idx')
        batch_op.drop_index('sso_domains_sso_provider_id_idx')

    op.drop_table('sso_domains', schema='auth')
    op.drop_table('migrations', schema='storage')
    with op.batch_alter_table('one_time_tokens', schema='auth') as batch_op:
        batch_op.drop_index('one_time_tokens_relates_to_hash_idx', postgresql_using='hash')
        batch_op.drop_index('one_time_tokens_token_hash_hash_idx', postgresql_using='hash')
        batch_op.drop_index('one_time_tokens_user_id_token_type_key')

    op.drop_table('one_time_tokens', schema='auth')
    with op.batch_alter_table('sessions', schema='auth') as batch_op:
        batch_op.drop_index('sessions_not_after_idx')
        batch_op.drop_index('sessions_user_id_idx')
        batch_op.drop_index('user_id_created_at_idx')

    op.drop_table('sessions', schema='auth')
    with op.batch_alter_table('flow_state', schema='auth') as batch_op:
        batch_op.drop_index('flow_state_created_at_idx')
        batch_op.drop_index('idx_auth_code')
        batch_op.drop_index('idx_user_id_auth_method')

    op.drop_table('flow_state', schema='auth')
    with op.batch_alter_table('buckets', schema='storage') as batch_op:
        batch_op.drop_index('bname')

    op.drop_table('buckets', schema='storage')
    with op.batch_alter_table('subscription', schema='realtime') as batch_op:
        batch_op.drop_index('ix_realtime_subscription_entity')
        batch_op.drop_index('subscription_subscription_id_entity_filters_key')

    op.drop_table('subscription', schema='realtime')
    with op.batch_alter_table('mfa_challenges', schema='auth') as batch_op:
        batch_op.drop_index('mfa_challenge_created_at_idx')

    op.drop_table('mfa_challenges', schema='auth')
    with op.batch_alter_table('sso_providers', schema='auth') as batch_op:
        batch_op.drop_index('sso_providers_resource_id_idx')
        batch_op.drop_index('sso_providers_resource_id_pattern_idx', postgresql_ops={'resource_id': 'text_pattern_ops'})

    op.drop_table('sso_providers', schema='auth')
    with op.batch_alter_table('refresh_tokens', schema='auth') as batch_op:
        batch_op.drop_index('refresh_tokens_instance_id_idx')
        batch_op.drop_index('refresh_tokens_instance_id_user_id_idx')
        batch_op.drop_index('refresh_tokens_parent_idx')
        batch_op.drop_index('refresh_tokens_session_id_revoked_idx')
        batch_op.drop_index('refresh_tokens_updated_at_idx')

    op.drop_table('refresh_tokens', schema='auth')
    with op.batch_alter_table('oauth_clients', schema='auth') as batch_op:
        batch_op.drop_index('oauth_clients_client_id_idx')
        batch_op.drop_index('oauth_clients_deleted_at_idx')

    op.drop_table('oauth_clients', schema='auth')
    op.drop_table('instances', schema='auth')
    with op.batch_alter_table('objects', schema='storage') as batch_op:
        batch_op.drop_index('bucketid_objname')
        batch_op.drop_index('idx_objects_bucket_id_name')
        batch_op.drop_index('name_prefix_search', postgresql_ops={'name': 'text_pattern_ops'})

    op.drop_table('objects', schema='storage')
    with op.batch_alter_table('analytics_cost_tracking', schema=None) as batch_op:
        batch_op.add_column(sa.Column('created_at', sa.DateTime(timezone=True), nullable=False, comment='Record creation timestamp (UTC)'))
        batch_op.add_column(sa.Column('updated_at', sa.DateTime(timezone=True), nullable=False, comment='Record last update timestamp (UTC)'))
        batch_op.add_column(sa.Column('deleted_at', sa.DateTime(timezone=True), nullable=True, comment='Soft delete timestamp (PIPEDA compliance)'))
        batch_op.add_column(sa.Column('is_deleted', sa.Boolean(), nullable=False, comment='Soft delete flag'))
        batch_op.add_column(sa.Column('created_by', sa.UUID(), nullable=True, comment='User who created this record'))
        batch_op.add_column(sa.Column('updated_by', sa.UUID(), nullable=True, comment='User who last updated this record'))
        batch_op.add_column(sa.Column('deleted_by', sa.UUID(), nullable=True, comment='User who deleted this record'))
        batch_op.alter_column('child_id',
               existing_type=sa.UUID(),
               comment='Child this cost tracking belongs to',
               existing_nullable=False)
        batch_op.alter_column('month_year',
               existing_type=sa.VARCHAR(length=7),
               comment='Month and year in format YYYY-MM',
               existing_nullable=False)
        batch_op.alter_column('total_cost_cad',
               existing_type=sa.NUMERIC(precision=10, scale=2),
               comment='Total monthly cost in CAD',
               existing_nullable=False)
        batch_op.alter_column('cost_per_change_cad',
               existing_type=sa.NUMERIC(precision=6, scale=4),
               comment='Average cost per diaper change in CAD',
               existing_nullable=False)
        batch_op.alter_column('efficiency_vs_target',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment='Efficiency percentage vs target cost',
               existing_nullable=True)
        batch_op.alter_column('weekend_vs_weekday_usage',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment='Weekend vs weekday usage percentage',
               existing_nullable=True)
        batch_op.alter_column('most_expensive_day',
               existing_type=sa.VARCHAR(length=9),
               comment='Day of week with highest costs',
               existing_nullable=True)
        batch_op.alter_column('cost_trend_7day',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment='7-day cost trend percentage',
               existing_nullable=True)
        batch_op.alter_column('primary_brand',
               existing_type=sa.VARCHAR(length=100),
               comment='Most used diaper brand this month',
               existing_nullable=True)
        batch_op.alter_column('primary_size',
               existing_type=sa.VARCHAR(length=10),
               comment='Most used diaper size this month',
               existing_nullable=True)
        batch_op.alter_column('brands_used',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Brands used this month {brand: count}',
               existing_nullable=True)
        batch_op.alter_column('sizes_used',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Sizes used this month {size: count}',
               existing_nullable=True)
        batch_op.alter_column('calculated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='When this cost analysis was calculated',
               existing_nullable=True)
        batch_op.alter_column('id',
               existing_type=sa.UUID(),
               comment='Unique identifier',
               existing_nullable=False)
        batch_op.drop_constraint('uq_analytics_cost_child_month', type_='unique')
        batch_op.create_index(batch_op.f('ix_analytics_cost_tracking_child_id'), ['child_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_analytics_cost_tracking_month_year'), ['month_year'], unique=False)
        batch_op.create_table_comment(
        'analytics_cost_tracking',
        'Monthly cost analysis and breakdown tracking',
        existing_comment=None,
        schema=None
    )

    with op.batch_alter_table('analytics_daily_summaries', schema=None) as batch_op:
        batch_op.add_column(sa.Column('deleted_at', sa.DateTime(timezone=True), nullable=True, comment='Soft delete timestamp (PIPEDA compliance)'))
        batch_op.add_column(sa.Column('is_deleted', sa.Boolean(), nullable=False, comment='Soft delete flag'))
        batch_op.add_column(sa.Column('created_by', sa.UUID(), nullable=True, comment='User who created this record'))
        batch_op.add_column(sa.Column('updated_by', sa.UUID(), nullable=True, comment='User who last updated this record'))
        batch_op.add_column(sa.Column('deleted_by', sa.UUID(), nullable=True, comment='User who deleted this record'))
        batch_op.alter_column('user_id',
               existing_type=sa.UUID(),
               comment='User this summary belongs to',
               existing_nullable=False)
        batch_op.alter_column('child_id',
               existing_type=sa.UUID(),
               comment='Child this summary belongs to',
               existing_nullable=False)
        batch_op.alter_column('date',
               existing_type=sa.DATE(),
               comment='Date for this daily summary',
               existing_nullable=False)
        batch_op.alter_column('total_changes',
               existing_type=sa.INTEGER(),
               comment='Total diaper changes for the day',
               existing_nullable=False)
        batch_op.alter_column('change_times',
               existing_type=postgresql.ARRAY(postgresql.TIMESTAMP(timezone=True)),
               comment='Array of timestamps when changes occurred',
               existing_nullable=False)
        batch_op.alter_column('hourly_distribution',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Distribution of changes by hour {hour: count}',
               existing_nullable=False)
        batch_op.alter_column('estimated_cost_cad',
               existing_type=sa.NUMERIC(precision=10, scale=2),
               comment='Estimated daily cost in CAD',
               existing_nullable=True)
        batch_op.alter_column('diaper_brand',
               existing_type=sa.VARCHAR(length=100),
               comment='Primary diaper brand used this day',
               existing_nullable=True)
        batch_op.alter_column('diaper_size',
               existing_type=sa.VARCHAR(length=10),
               comment='Primary diaper size used this day',
               existing_nullable=True)
        batch_op.alter_column('time_between_changes_avg',
               existing_type=postgresql.INTERVAL(),
               comment='Average time between diaper changes',
               existing_nullable=True)
        batch_op.alter_column('longest_gap',
               existing_type=postgresql.INTERVAL(),
               comment='Longest gap between changes',
               existing_nullable=True)
        batch_op.alter_column('shortest_gap',
               existing_type=postgresql.INTERVAL(),
               comment='Shortest gap between changes',
               existing_nullable=True)
        batch_op.alter_column('created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='When this summary was created',
               existing_nullable=True)
        batch_op.alter_column('updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='When this summary was last updated',
               existing_nullable=True)
        batch_op.alter_column('id',
               existing_type=sa.UUID(),
               comment='Unique identifier',
               existing_nullable=False)
        batch_op.drop_constraint('uq_analytics_daily_child_date', type_='unique')
        batch_op.create_index(batch_op.f('ix_analytics_daily_summaries_child_id'), ['child_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_analytics_daily_summaries_date'), ['date'], unique=False)
        batch_op.create_index(batch_op.f('ix_analytics_daily_summaries_user_id'), ['user_id'], unique=False)
        batch_op.drop_constraint('analytics_daily_summaries_user_id_fkey', type_='foreignkey')
        batch_op.create_foreign_key(None, 'users', ['user_id'], ['id'], ondelete='CASCADE')
        batch_op.create_table_comment(
        'analytics_daily_summaries',
        'Daily analytics summaries for performance optimization',
        existing_comment=None,
        schema=None
    )

    with op.batch_alter_table('analytics_weekly_patterns', schema=None) as batch_op:
        batch_op.add_column(sa.Column('created_at', sa.DateTime(timezone=True), nullable=False, comment='Record creation timestamp (UTC)'))
        batch_op.add_column(sa.Column('updated_at', sa.DateTime(timezone=True), nullable=False, comment='Record last update timestamp (UTC)'))
        batch_op.add_column(sa.Column('deleted_at', sa.DateTime(timezone=True), nullable=True, comment='Soft delete timestamp (PIPEDA compliance)'))
        batch_op.add_column(sa.Column('is_deleted', sa.Boolean(), nullable=False, comment='Soft delete flag'))
        batch_op.add_column(sa.Column('created_by', sa.UUID(), nullable=True, comment='User who created this record'))
        batch_op.add_column(sa.Column('updated_by', sa.UUID(), nullable=True, comment='User who last updated this record'))
        batch_op.add_column(sa.Column('deleted_by', sa.UUID(), nullable=True, comment='User who deleted this record'))
        batch_op.alter_column('child_id',
               existing_type=sa.UUID(),
               comment='Child this pattern belongs to',
               existing_nullable=False)
        batch_op.alter_column('week_start_date',
               existing_type=sa.DATE(),
               comment='Start date of the week (Monday)',
               existing_nullable=False)
        batch_op.alter_column('daily_counts',
               existing_type=postgresql.ARRAY(sa.INTEGER()),
               comment='Daily change counts [Mon, Tue, Wed, Thu, Fri, Sat, Sun]',
               existing_nullable=False)
        batch_op.alter_column('weekly_average',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment='Average changes per day for the week',
               existing_nullable=False)
        batch_op.alter_column('consistency_percentage',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment='Pattern consistency percentage (0-100)',
               existing_nullable=False)
        batch_op.alter_column('pattern_insights',
               existing_type=sa.TEXT(),
               comment='Human-readable pattern insights',
               existing_nullable=True)
        batch_op.alter_column('peak_hours',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Peak hours analysis {time_range: percentage}',
               existing_nullable=False)
        batch_op.alter_column('hourly_distribution',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='24-hour distribution data',
               existing_nullable=False)
        batch_op.alter_column('weekday_average',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment='Average changes per weekday',
               existing_nullable=True)
        batch_op.alter_column('weekend_average',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment='Average changes per weekend day',
               existing_nullable=True)
        batch_op.alter_column('weekend_vs_weekday_ratio',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment='Weekend vs weekday usage ratio',
               existing_nullable=True)
        batch_op.alter_column('calculated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='When this pattern was calculated',
               existing_nullable=True)
        batch_op.alter_column('data_quality_score',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment='Data quality score (0-100)',
               existing_nullable=True)
        batch_op.alter_column('id',
               existing_type=sa.UUID(),
               comment='Unique identifier',
               existing_nullable=False)
        batch_op.drop_constraint('uq_analytics_weekly_child_week', type_='unique')
        batch_op.create_index(batch_op.f('ix_analytics_weekly_patterns_child_id'), ['child_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_analytics_weekly_patterns_week_start_date'), ['week_start_date'], unique=False)
        batch_op.create_table_comment(
        'analytics_weekly_patterns',
        'Weekly pattern cache for performance optimization',
        existing_comment=None,
        schema=None
    )

    with op.batch_alter_table('children', schema=None) as batch_op:
        batch_op.add_column(sa.Column('family_id', sa.UUID(), nullable=True, comment='Family ID for collaboration'))
        batch_op.add_column(sa.Column('migrated_from_user', sa.UUID(), nullable=True, comment='Original parent user ID before family migration'))
        batch_op.alter_column('parent_id',
               existing_type=sa.UUID(),
               comment='Parent user ID (legacy - deprecated in favor of family model)',
               existing_comment='Parent user ID',
               existing_nullable=False)
        batch_op.drop_index('idx_children_current_size')
        batch_op.drop_index('idx_children_date_of_birth')
        batch_op.drop_index('idx_children_onboarding')
        batch_op.drop_index('idx_children_parent_id_active', postgresql_where='(is_deleted = false)')
        batch_op.create_index(batch_op.f('ix_children_family_id'), ['family_id'], unique=False)
        batch_op.create_foreign_key(None, 'families', ['family_id'], ['id'], ondelete='CASCADE')
        batch_op.drop_table_comment(
        'children',
        existing_comment='Child profiles for diaper planning with Canadian privacy compliance',
        schema=None
    )

    with op.batch_alter_table('consent_audit_logs', schema=None) as batch_op:
        batch_op.add_column(sa.Column('audit_metadata', sa.JSON(), nullable=True, comment='Additional metadata about the action'))
        batch_op.drop_index('idx_consent_audit_logs_action')
        batch_op.drop_index('idx_consent_audit_logs_consent_record')
        batch_op.drop_index('idx_consent_audit_logs_user_id_created')
        batch_op.drop_table_comment(
        'consent_audit_logs',
        existing_comment='Comprehensive audit log for all consent-related activities',
        schema=None
    )
        batch_op.drop_column('metadata')

    with op.batch_alter_table('consent_records', schema=None) as batch_op:
        batch_op.drop_index('idx_consent_records_expires_at')
        batch_op.drop_index('idx_consent_records_granted_at')
        batch_op.drop_index('idx_consent_records_status')
        batch_op.drop_index('idx_consent_records_user_type')
        batch_op.drop_table_comment(
        'consent_records',
        existing_comment='PIPEDA-compliant consent records with full audit trail',
        schema=None
    )

    with op.batch_alter_table('growth_predictions', schema=None) as batch_op:
        batch_op.add_column(sa.Column('created_at', sa.DateTime(timezone=True), nullable=False, comment='Record creation timestamp (UTC)'))
        batch_op.add_column(sa.Column('updated_at', sa.DateTime(timezone=True), nullable=False, comment='Record last update timestamp (UTC)'))
        batch_op.add_column(sa.Column('deleted_at', sa.DateTime(timezone=True), nullable=True, comment='Soft delete timestamp (PIPEDA compliance)'))
        batch_op.add_column(sa.Column('is_deleted', sa.Boolean(), nullable=False, comment='Soft delete flag'))
        batch_op.add_column(sa.Column('created_by', sa.UUID(), nullable=True, comment='User who created this record'))
        batch_op.add_column(sa.Column('updated_by', sa.UUID(), nullable=True, comment='User who last updated this record'))
        batch_op.add_column(sa.Column('deleted_by', sa.UUID(), nullable=True, comment='User who deleted this record'))
        batch_op.alter_column('child_id',
               existing_type=sa.UUID(),
               comment='Child this prediction belongs to',
               existing_nullable=False)
        batch_op.alter_column('prediction_date_range',
               existing_type=sa.VARCHAR(length=50),
               comment="Predicted date range for size change (e.g., 'Jan 25-30')",
               existing_nullable=False)
        batch_op.alter_column('confidence_score',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment='Prediction confidence score (0-100)',
               existing_nullable=False)
        batch_op.alter_column('growth_velocity_cm_week',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment='Growth velocity in cm per week',
               existing_nullable=True)
        batch_op.alter_column('current_fit_efficiency',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment='Current diaper size fit efficiency percentage',
               existing_nullable=True)
        batch_op.alter_column('current_size',
               existing_type=sa.VARCHAR(length=10),
               comment='Current diaper size',
               existing_nullable=True)
        batch_op.alter_column('next_size_recommendation',
               existing_type=sa.VARCHAR(length=10),
               comment='Recommended next size',
               existing_nullable=True)
        batch_op.alter_column('prediction_basis',
               existing_type=sa.TEXT(),
               comment='Data points and factors used for prediction',
               existing_nullable=True)
        batch_op.alter_column('model_version',
               existing_type=sa.VARCHAR(length=20),
               comment='ML model version used for prediction',
               existing_nullable=True)
        batch_op.alter_column('training_data_points',
               existing_type=sa.INTEGER(),
               comment='Number of data points used for training',
               existing_nullable=True)
        batch_op.alter_column('prediction_created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='When this prediction was created',
               existing_nullable=True)
        batch_op.alter_column('expires_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='When this prediction expires',
               existing_nullable=False)
        batch_op.alter_column('id',
               existing_type=sa.UUID(),
               comment='Unique identifier',
               existing_nullable=False)
        batch_op.drop_constraint('uq_growth_predictions_child', type_='unique')
        batch_op.create_index(batch_op.f('ix_growth_predictions_child_id'), ['child_id'], unique=False)
        batch_op.create_table_comment(
        'growth_predictions',
        'ML-based growth and size change predictions',
        existing_comment=None,
        schema=None
    )

    with op.batch_alter_table('inventory_items', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_inventory_items_child_id'), ['child_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_inventory_items_product_type'), ['product_type'], unique=False)
        batch_op.create_index(batch_op.f('ix_inventory_items_size'), ['size'], unique=False)

    with op.batch_alter_table('notification_delivery_log', schema=None) as batch_op:
        batch_op.alter_column('user_id',
               existing_type=sa.UUID(),
               comment='Target user ID',
               existing_nullable=False)
        batch_op.alter_column('queue_item_id',
               existing_type=sa.UUID(),
               comment='Associated queue item ID',
               existing_nullable=True)
        batch_op.alter_column('preferences_id',
               existing_type=sa.UUID(),
               comment='User preferences at time of delivery',
               existing_nullable=True)
        batch_op.alter_column('notification_type',
               existing_type=postgresql.ENUM('stock_alert', 'diaper_change_reminder', 'expiry_warning', 'health_tip', 'system_update', 'marketing', name='notificationtypeenum'),
               comment='Type of notification delivered',
               existing_nullable=False)
        batch_op.alter_column('priority',
               existing_type=postgresql.ENUM('critical', 'important', 'optional', name='notificationprioritytype'),
               comment='Priority level at delivery',
               existing_nullable=False)
        batch_op.alter_column('channel',
               existing_type=postgresql.ENUM('push', 'email', 'sms', 'in_app', name='notificationchannelenum'),
               comment='Delivery channel used',
               existing_nullable=False)
        batch_op.alter_column('title',
               existing_type=sa.VARCHAR(length=200),
               comment='Notification title delivered',
               existing_nullable=False)
        batch_op.alter_column('message',
               existing_type=sa.TEXT(),
               comment='Message content delivered',
               existing_nullable=False)
        batch_op.alter_column('delivery_status',
               existing_type=postgresql.ENUM('pending', 'sent', 'delivered', 'failed', 'cancelled', name='notificationstatusenum'),
               comment='Final delivery status',
               existing_nullable=False)
        batch_op.alter_column('sent_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='When notification was sent',
               existing_nullable=True)
        batch_op.alter_column('delivered_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='When notification was confirmed delivered',
               existing_nullable=True)
        batch_op.alter_column('external_id',
               existing_type=sa.VARCHAR(length=255),
               comment='External service notification ID (OneSignal, etc.)',
               existing_nullable=True)
        batch_op.alter_column('external_response',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='External service response data',
               existing_nullable=True)
        batch_op.alter_column('error_code',
               existing_type=sa.VARCHAR(length=50),
               comment='Error code if delivery failed',
               existing_nullable=True)
        batch_op.alter_column('error_message',
               existing_type=sa.TEXT(),
               comment='Error message if delivery failed',
               existing_nullable=True)
        batch_op.alter_column('processing_time_ms',
               existing_type=sa.INTEGER(),
               comment='Processing time in milliseconds',
               existing_nullable=True)
        batch_op.alter_column('data_retention_date',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='When this log entry should be purged (PIPEDA compliance)',
               existing_nullable=True)
        batch_op.alter_column('opened_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='When user opened notification',
               existing_nullable=True)
        batch_op.alter_column('clicked_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='When user clicked notification',
               existing_nullable=True)
        batch_op.alter_column('dismissed_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='When user dismissed notification',
               existing_nullable=True)
        batch_op.alter_column('id',
               existing_type=sa.UUID(),
               server_default=None,
               comment='Unique identifier',
               existing_nullable=False)
        batch_op.alter_column('created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=None,
               comment='Record creation timestamp (UTC)',
               existing_nullable=False)
        batch_op.alter_column('updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=None,
               comment='Record last update timestamp (UTC)',
               existing_nullable=False)
        batch_op.alter_column('deleted_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='Soft delete timestamp (PIPEDA compliance)',
               existing_nullable=True)
        batch_op.alter_column('is_deleted',
               existing_type=sa.BOOLEAN(),
               comment='Soft delete flag',
               existing_nullable=False)
        batch_op.alter_column('created_by',
               existing_type=sa.UUID(),
               comment='User who created this record',
               existing_nullable=True)
        batch_op.alter_column('updated_by',
               existing_type=sa.UUID(),
               comment='User who last updated this record',
               existing_nullable=True)
        batch_op.alter_column('deleted_by',
               existing_type=sa.UUID(),
               comment='User who deleted this record',
               existing_nullable=True)
        batch_op.drop_column('data_version')
        batch_op.drop_column('deletion_reason')
        batch_op.drop_column('data_source')

    with op.batch_alter_table('notification_preferences', schema=None) as batch_op:
        batch_op.alter_column('user_id',
               existing_type=sa.UUID(),
               comment='Associated user ID',
               existing_nullable=False)
        batch_op.alter_column('notifications_enabled',
               existing_type=sa.BOOLEAN(),
               comment='Master toggle for all notifications',
               existing_nullable=False)
        batch_op.alter_column('critical_notifications',
               existing_type=sa.BOOLEAN(),
               comment='Allow critical notifications (out of stock, urgent)',
               existing_nullable=False)
        batch_op.alter_column('important_notifications',
               existing_type=sa.BOOLEAN(),
               comment='Allow important notifications (low stock, warnings)',
               existing_nullable=False)
        batch_op.alter_column('optional_notifications',
               existing_type=sa.BOOLEAN(),
               comment='Allow optional notifications (tips, promotions)',
               existing_nullable=False)
        batch_op.alter_column('push_notifications',
               existing_type=sa.BOOLEAN(),
               comment='Allow push notifications',
               existing_nullable=False)
        batch_op.alter_column('email_notifications',
               existing_type=sa.BOOLEAN(),
               comment='Allow email notifications',
               existing_nullable=False)
        batch_op.alter_column('sms_notifications',
               existing_type=sa.BOOLEAN(),
               comment='Allow SMS notifications (future feature)',
               existing_nullable=False)
        batch_op.alter_column('quiet_hours_enabled',
               existing_type=sa.BOOLEAN(),
               comment='Enable quiet hours for non-critical notifications',
               existing_nullable=False)
        batch_op.alter_column('quiet_hours_start',
               existing_type=postgresql.TIME(),
               comment='Quiet hours start time (local timezone)',
               existing_nullable=True)
        batch_op.alter_column('quiet_hours_end',
               existing_type=postgresql.TIME(),
               comment='Quiet hours end time (local timezone)',
               existing_nullable=True)
        batch_op.alter_column('stock_alert_enabled',
               existing_type=sa.BOOLEAN(),
               comment='Enable inventory stock alerts',
               existing_nullable=False)
        batch_op.alter_column('stock_alert_threshold',
               existing_type=sa.INTEGER(),
               comment='Days remaining threshold for stock alerts',
               existing_nullable=True)
        batch_op.alter_column('change_reminder_enabled',
               existing_type=sa.BOOLEAN(),
               comment='Enable diaper change reminders',
               existing_nullable=False)
        batch_op.alter_column('change_reminder_interval_hours',
               existing_type=sa.INTEGER(),
               comment='Hours between change reminders',
               existing_nullable=True)
        batch_op.alter_column('expiry_warning_enabled',
               existing_type=sa.BOOLEAN(),
               comment='Enable product expiry warnings',
               existing_nullable=False)
        batch_op.alter_column('expiry_warning_days',
               existing_type=sa.INTEGER(),
               comment='Days before expiry to send warning',
               existing_nullable=True)
        batch_op.alter_column('health_tips_enabled',
               existing_type=sa.BOOLEAN(),
               comment='Enable health and parenting tips',
               existing_nullable=False)
        batch_op.alter_column('marketing_enabled',
               existing_type=sa.BOOLEAN(),
               comment='Enable marketing and promotional notifications',
               existing_nullable=False)
        batch_op.alter_column('device_tokens',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='OneSignal device tokens for push notifications',
               existing_nullable=True)
        batch_op.alter_column('user_timezone',
               existing_type=sa.VARCHAR(length=50),
               comment='User timezone for notification scheduling',
               existing_nullable=False)
        batch_op.alter_column('daily_notification_limit',
               existing_type=sa.INTEGER(),
               comment='Maximum notifications per day',
               existing_nullable=False)
        batch_op.alter_column('notification_consent_granted',
               existing_type=sa.BOOLEAN(),
               comment='Explicit consent for notifications granted',
               existing_nullable=False)
        batch_op.alter_column('notification_consent_date',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='When notification consent was granted',
               existing_nullable=True)
        batch_op.alter_column('marketing_consent_granted',
               existing_type=sa.BOOLEAN(),
               comment='Explicit consent for marketing notifications',
               existing_nullable=False)
        batch_op.alter_column('marketing_consent_date',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='When marketing consent was granted',
               existing_nullable=True)
        batch_op.alter_column('id',
               existing_type=sa.UUID(),
               server_default=None,
               comment='Unique identifier',
               existing_nullable=False)
        batch_op.alter_column('created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=None,
               comment='Record creation timestamp (UTC)',
               existing_nullable=False)
        batch_op.alter_column('updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=None,
               comment='Record last update timestamp (UTC)',
               existing_nullable=False)
        batch_op.alter_column('deleted_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='Soft delete timestamp (PIPEDA compliance)',
               existing_nullable=True)
        batch_op.alter_column('is_deleted',
               existing_type=sa.BOOLEAN(),
               comment='Soft delete flag',
               existing_nullable=False)
        batch_op.alter_column('created_by',
               existing_type=sa.UUID(),
               comment='User who created this record',
               existing_nullable=True)
        batch_op.alter_column('updated_by',
               existing_type=sa.UUID(),
               comment='User who last updated this record',
               existing_nullable=True)
        batch_op.alter_column('deleted_by',
               existing_type=sa.UUID(),
               comment='User who deleted this record',
               existing_nullable=True)
        batch_op.drop_column('data_version')
        batch_op.drop_column('deletion_reason')
        batch_op.drop_column('data_source')

    with op.batch_alter_table('notification_queue', schema=None) as batch_op:
        batch_op.alter_column('user_id',
               existing_type=sa.UUID(),
               comment='Target user ID',
               existing_nullable=False)
        batch_op.alter_column('child_id',
               existing_type=sa.UUID(),
               comment='Associated child ID (optional)',
               existing_nullable=True)
        batch_op.alter_column('notification_type',
               existing_type=postgresql.ENUM('stock_alert', 'diaper_change_reminder', 'expiry_warning', 'health_tip', 'system_update', 'marketing', name='notificationtypeenum'),
               comment='Type of notification',
               existing_nullable=False)
        batch_op.alter_column('priority',
               existing_type=postgresql.ENUM('critical', 'important', 'optional', name='notificationprioritytype'),
               comment='Notification priority level',
               existing_nullable=False)
        batch_op.alter_column('channels',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Delivery channels as JSON array',
               existing_nullable=False)
        batch_op.alter_column('title',
               existing_type=sa.VARCHAR(length=200),
               comment='Notification title',
               existing_nullable=False)
        batch_op.alter_column('message',
               existing_type=sa.TEXT(),
               comment='Notification message body',
               existing_nullable=False)
        batch_op.alter_column('data_payload',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment='Additional notification data as JSON',
               existing_nullable=True)
        batch_op.alter_column('scheduled_for',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='When notification should be sent',
               existing_nullable=False)
        batch_op.alter_column('status',
               existing_type=postgresql.ENUM('pending', 'sent', 'delivered', 'failed', 'cancelled', name='notificationstatusenum'),
               comment='Current notification status',
               existing_nullable=False)
        batch_op.alter_column('attempts',
               existing_type=sa.INTEGER(),
               comment='Number of delivery attempts',
               existing_nullable=False)
        batch_op.alter_column('max_attempts',
               existing_type=sa.INTEGER(),
               comment='Maximum delivery attempts',
               existing_nullable=False)
        batch_op.alter_column('last_error',
               existing_type=sa.TEXT(),
               comment='Last delivery error message',
               existing_nullable=True)
        batch_op.alter_column('batch_id',
               existing_type=sa.UUID(),
               comment='Batch processing ID',
               existing_nullable=True)
        batch_op.alter_column('id',
               existing_type=sa.UUID(),
               server_default=None,
               comment='Unique identifier',
               existing_nullable=False)
        batch_op.alter_column('created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=None,
               comment='Record creation timestamp (UTC)',
               existing_nullable=False)
        batch_op.alter_column('updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=None,
               comment='Record last update timestamp (UTC)',
               existing_nullable=False)
        batch_op.alter_column('deleted_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment='Soft delete timestamp (PIPEDA compliance)',
               existing_nullable=True)
        batch_op.alter_column('is_deleted',
               existing_type=sa.BOOLEAN(),
               comment='Soft delete flag',
               existing_nullable=False)
        batch_op.alter_column('created_by',
               existing_type=sa.UUID(),
               comment='User who created this record',
               existing_nullable=True)
        batch_op.alter_column('updated_by',
               existing_type=sa.UUID(),
               comment='User who last updated this record',
               existing_nullable=True)
        batch_op.alter_column('deleted_by',
               existing_type=sa.UUID(),
               comment='User who deleted this record',
               existing_nullable=True)
        batch_op.drop_column('data_version')
        batch_op.drop_column('deletion_reason')
        batch_op.drop_column('data_source')

    with op.batch_alter_table('stock_thresholds', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_stock_thresholds_child_id'), ['child_id'], unique=False)

    with op.batch_alter_table('usage_logs', schema=None) as batch_op:
        batch_op.drop_index('idx_usage_logs_analytics', postgresql_where='(deleted_at IS NULL)')
        batch_op.create_index(batch_op.f('ix_usage_logs_child_id'), ['child_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_usage_logs_inventory_item_id'), ['inventory_item_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_usage_logs_logged_at'), ['logged_at'], unique=False)
        batch_op.create_index(batch_op.f('ix_usage_logs_usage_type'), ['usage_type'], unique=False)
        batch_op.drop_column('diaper_size')
        batch_op.drop_column('fit_rating')
        batch_op.drop_column('estimated_cost_cad')
        batch_op.drop_column('diaper_brand')
        batch_op.drop_column('efficiency_notes')

    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.drop_index('idx_users_created_at')
        batch_op.drop_index('idx_users_email_active', postgresql_where='(is_deleted = false)')
        batch_op.drop_index('idx_users_province')
        batch_op.drop_index('idx_users_status')
        batch_op.drop_index('idx_users_supabase_id_active', postgresql_where='(is_deleted = false)')
        batch_op.drop_table_comment(
        'users',
        existing_comment='PIPEDA-compliant user accounts with Canadian data sovereignty',
        schema=None
    )

    # ### end Alembic commands ###


def downgrade() -> None:
    """
    Reverse migration changes
    
    PIPEDA Compliance Notes:
    - Data rollback maintains compliance requirements
    - Audit logs are preserved even during rollback
    - No personal data is inadvertently exposed during downgrade
    """
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.create_table_comment(
        'users',
        'PIPEDA-compliant user accounts with Canadian data sovereignty',
        existing_comment=None,
        schema=None
    )
        batch_op.create_index('idx_users_supabase_id_active', ['supabase_user_id'], unique=False, postgresql_where='(is_deleted = false)')
        batch_op.create_index('idx_users_status', ['status'], unique=False)
        batch_op.create_index('idx_users_province', ['province'], unique=False)
        batch_op.create_index('idx_users_email_active', ['email'], unique=False, postgresql_where='(is_deleted = false)')
        batch_op.create_index('idx_users_created_at', ['created_at'], unique=False)

    with op.batch_alter_table('usage_logs', schema=None) as batch_op:
        batch_op.add_column(sa.Column('efficiency_notes', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('diaper_brand', sa.VARCHAR(length=100), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('estimated_cost_cad', sa.NUMERIC(precision=6, scale=4), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('fit_rating', sa.INTEGER(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('diaper_size', sa.VARCHAR(length=10), autoincrement=False, nullable=True))
        batch_op.drop_index(batch_op.f('ix_usage_logs_usage_type'))
        batch_op.drop_index(batch_op.f('ix_usage_logs_logged_at'))
        batch_op.drop_index(batch_op.f('ix_usage_logs_inventory_item_id'))
        batch_op.drop_index(batch_op.f('ix_usage_logs_child_id'))
        batch_op.create_index('idx_usage_logs_analytics', ['child_id', 'created_at'], unique=False, postgresql_where='(deleted_at IS NULL)')

    with op.batch_alter_table('stock_thresholds', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_stock_thresholds_child_id'))

    with op.batch_alter_table('notification_queue', schema=None) as batch_op:
        batch_op.add_column(sa.Column('data_source', sa.VARCHAR(length=100), autoincrement=False, nullable=False))
        batch_op.add_column(sa.Column('deletion_reason', sa.VARCHAR(length=255), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('data_version', sa.INTEGER(), autoincrement=False, nullable=False))
        batch_op.alter_column('deleted_by',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='User who deleted this record',
               existing_nullable=True)
        batch_op.alter_column('updated_by',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='User who last updated this record',
               existing_nullable=True)
        batch_op.alter_column('created_by',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='User who created this record',
               existing_nullable=True)
        batch_op.alter_column('is_deleted',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Soft delete flag',
               existing_nullable=False)
        batch_op.alter_column('deleted_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='Soft delete timestamp (PIPEDA compliance)',
               existing_nullable=True)
        batch_op.alter_column('updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=sa.text('now()'),
               comment=None,
               existing_comment='Record last update timestamp (UTC)',
               existing_nullable=False)
        batch_op.alter_column('created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=sa.text('now()'),
               comment=None,
               existing_comment='Record creation timestamp (UTC)',
               existing_nullable=False)
        batch_op.alter_column('id',
               existing_type=sa.UUID(),
               server_default=sa.text('gen_random_uuid()'),
               comment=None,
               existing_comment='Unique identifier',
               existing_nullable=False)
        batch_op.alter_column('batch_id',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='Batch processing ID',
               existing_nullable=True)
        batch_op.alter_column('last_error',
               existing_type=sa.TEXT(),
               comment=None,
               existing_comment='Last delivery error message',
               existing_nullable=True)
        batch_op.alter_column('max_attempts',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Maximum delivery attempts',
               existing_nullable=False)
        batch_op.alter_column('attempts',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Number of delivery attempts',
               existing_nullable=False)
        batch_op.alter_column('status',
               existing_type=postgresql.ENUM('pending', 'sent', 'delivered', 'failed', 'cancelled', name='notificationstatusenum'),
               comment=None,
               existing_comment='Current notification status',
               existing_nullable=False)
        batch_op.alter_column('scheduled_for',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='When notification should be sent',
               existing_nullable=False)
        batch_op.alter_column('data_payload',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment=None,
               existing_comment='Additional notification data as JSON',
               existing_nullable=True)
        batch_op.alter_column('message',
               existing_type=sa.TEXT(),
               comment=None,
               existing_comment='Notification message body',
               existing_nullable=False)
        batch_op.alter_column('title',
               existing_type=sa.VARCHAR(length=200),
               comment=None,
               existing_comment='Notification title',
               existing_nullable=False)
        batch_op.alter_column('channels',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment=None,
               existing_comment='Delivery channels as JSON array',
               existing_nullable=False)
        batch_op.alter_column('priority',
               existing_type=postgresql.ENUM('critical', 'important', 'optional', name='notificationprioritytype'),
               comment=None,
               existing_comment='Notification priority level',
               existing_nullable=False)
        batch_op.alter_column('notification_type',
               existing_type=postgresql.ENUM('stock_alert', 'diaper_change_reminder', 'expiry_warning', 'health_tip', 'system_update', 'marketing', name='notificationtypeenum'),
               comment=None,
               existing_comment='Type of notification',
               existing_nullable=False)
        batch_op.alter_column('child_id',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='Associated child ID (optional)',
               existing_nullable=True)
        batch_op.alter_column('user_id',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='Target user ID',
               existing_nullable=False)

    with op.batch_alter_table('notification_preferences', schema=None) as batch_op:
        batch_op.add_column(sa.Column('data_source', sa.VARCHAR(length=100), autoincrement=False, nullable=False))
        batch_op.add_column(sa.Column('deletion_reason', sa.VARCHAR(length=255), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('data_version', sa.INTEGER(), autoincrement=False, nullable=False))
        batch_op.alter_column('deleted_by',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='User who deleted this record',
               existing_nullable=True)
        batch_op.alter_column('updated_by',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='User who last updated this record',
               existing_nullable=True)
        batch_op.alter_column('created_by',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='User who created this record',
               existing_nullable=True)
        batch_op.alter_column('is_deleted',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Soft delete flag',
               existing_nullable=False)
        batch_op.alter_column('deleted_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='Soft delete timestamp (PIPEDA compliance)',
               existing_nullable=True)
        batch_op.alter_column('updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=sa.text('now()'),
               comment=None,
               existing_comment='Record last update timestamp (UTC)',
               existing_nullable=False)
        batch_op.alter_column('created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=sa.text('now()'),
               comment=None,
               existing_comment='Record creation timestamp (UTC)',
               existing_nullable=False)
        batch_op.alter_column('id',
               existing_type=sa.UUID(),
               server_default=sa.text('gen_random_uuid()'),
               comment=None,
               existing_comment='Unique identifier',
               existing_nullable=False)
        batch_op.alter_column('marketing_consent_date',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='When marketing consent was granted',
               existing_nullable=True)
        batch_op.alter_column('marketing_consent_granted',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Explicit consent for marketing notifications',
               existing_nullable=False)
        batch_op.alter_column('notification_consent_date',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='When notification consent was granted',
               existing_nullable=True)
        batch_op.alter_column('notification_consent_granted',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Explicit consent for notifications granted',
               existing_nullable=False)
        batch_op.alter_column('daily_notification_limit',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Maximum notifications per day',
               existing_nullable=False)
        batch_op.alter_column('user_timezone',
               existing_type=sa.VARCHAR(length=50),
               comment=None,
               existing_comment='User timezone for notification scheduling',
               existing_nullable=False)
        batch_op.alter_column('device_tokens',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment=None,
               existing_comment='OneSignal device tokens for push notifications',
               existing_nullable=True)
        batch_op.alter_column('marketing_enabled',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Enable marketing and promotional notifications',
               existing_nullable=False)
        batch_op.alter_column('health_tips_enabled',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Enable health and parenting tips',
               existing_nullable=False)
        batch_op.alter_column('expiry_warning_days',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Days before expiry to send warning',
               existing_nullable=True)
        batch_op.alter_column('expiry_warning_enabled',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Enable product expiry warnings',
               existing_nullable=False)
        batch_op.alter_column('change_reminder_interval_hours',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Hours between change reminders',
               existing_nullable=True)
        batch_op.alter_column('change_reminder_enabled',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Enable diaper change reminders',
               existing_nullable=False)
        batch_op.alter_column('stock_alert_threshold',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Days remaining threshold for stock alerts',
               existing_nullable=True)
        batch_op.alter_column('stock_alert_enabled',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Enable inventory stock alerts',
               existing_nullable=False)
        batch_op.alter_column('quiet_hours_end',
               existing_type=postgresql.TIME(),
               comment=None,
               existing_comment='Quiet hours end time (local timezone)',
               existing_nullable=True)
        batch_op.alter_column('quiet_hours_start',
               existing_type=postgresql.TIME(),
               comment=None,
               existing_comment='Quiet hours start time (local timezone)',
               existing_nullable=True)
        batch_op.alter_column('quiet_hours_enabled',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Enable quiet hours for non-critical notifications',
               existing_nullable=False)
        batch_op.alter_column('sms_notifications',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Allow SMS notifications (future feature)',
               existing_nullable=False)
        batch_op.alter_column('email_notifications',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Allow email notifications',
               existing_nullable=False)
        batch_op.alter_column('push_notifications',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Allow push notifications',
               existing_nullable=False)
        batch_op.alter_column('optional_notifications',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Allow optional notifications (tips, promotions)',
               existing_nullable=False)
        batch_op.alter_column('important_notifications',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Allow important notifications (low stock, warnings)',
               existing_nullable=False)
        batch_op.alter_column('critical_notifications',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Allow critical notifications (out of stock, urgent)',
               existing_nullable=False)
        batch_op.alter_column('notifications_enabled',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Master toggle for all notifications',
               existing_nullable=False)
        batch_op.alter_column('user_id',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='Associated user ID',
               existing_nullable=False)

    with op.batch_alter_table('notification_delivery_log', schema=None) as batch_op:
        batch_op.add_column(sa.Column('data_source', sa.VARCHAR(length=100), autoincrement=False, nullable=False))
        batch_op.add_column(sa.Column('deletion_reason', sa.VARCHAR(length=255), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('data_version', sa.INTEGER(), autoincrement=False, nullable=False))
        batch_op.alter_column('deleted_by',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='User who deleted this record',
               existing_nullable=True)
        batch_op.alter_column('updated_by',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='User who last updated this record',
               existing_nullable=True)
        batch_op.alter_column('created_by',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='User who created this record',
               existing_nullable=True)
        batch_op.alter_column('is_deleted',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Soft delete flag',
               existing_nullable=False)
        batch_op.alter_column('deleted_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='Soft delete timestamp (PIPEDA compliance)',
               existing_nullable=True)
        batch_op.alter_column('updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=sa.text('now()'),
               comment=None,
               existing_comment='Record last update timestamp (UTC)',
               existing_nullable=False)
        batch_op.alter_column('created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               server_default=sa.text('now()'),
               comment=None,
               existing_comment='Record creation timestamp (UTC)',
               existing_nullable=False)
        batch_op.alter_column('id',
               existing_type=sa.UUID(),
               server_default=sa.text('gen_random_uuid()'),
               comment=None,
               existing_comment='Unique identifier',
               existing_nullable=False)
        batch_op.alter_column('dismissed_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='When user dismissed notification',
               existing_nullable=True)
        batch_op.alter_column('clicked_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='When user clicked notification',
               existing_nullable=True)
        batch_op.alter_column('opened_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='When user opened notification',
               existing_nullable=True)
        batch_op.alter_column('data_retention_date',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='When this log entry should be purged (PIPEDA compliance)',
               existing_nullable=True)
        batch_op.alter_column('processing_time_ms',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Processing time in milliseconds',
               existing_nullable=True)
        batch_op.alter_column('error_message',
               existing_type=sa.TEXT(),
               comment=None,
               existing_comment='Error message if delivery failed',
               existing_nullable=True)
        batch_op.alter_column('error_code',
               existing_type=sa.VARCHAR(length=50),
               comment=None,
               existing_comment='Error code if delivery failed',
               existing_nullable=True)
        batch_op.alter_column('external_response',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment=None,
               existing_comment='External service response data',
               existing_nullable=True)
        batch_op.alter_column('external_id',
               existing_type=sa.VARCHAR(length=255),
               comment=None,
               existing_comment='External service notification ID (OneSignal, etc.)',
               existing_nullable=True)
        batch_op.alter_column('delivered_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='When notification was confirmed delivered',
               existing_nullable=True)
        batch_op.alter_column('sent_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='When notification was sent',
               existing_nullable=True)
        batch_op.alter_column('delivery_status',
               existing_type=postgresql.ENUM('pending', 'sent', 'delivered', 'failed', 'cancelled', name='notificationstatusenum'),
               comment=None,
               existing_comment='Final delivery status',
               existing_nullable=False)
        batch_op.alter_column('message',
               existing_type=sa.TEXT(),
               comment=None,
               existing_comment='Message content delivered',
               existing_nullable=False)
        batch_op.alter_column('title',
               existing_type=sa.VARCHAR(length=200),
               comment=None,
               existing_comment='Notification title delivered',
               existing_nullable=False)
        batch_op.alter_column('channel',
               existing_type=postgresql.ENUM('push', 'email', 'sms', 'in_app', name='notificationchannelenum'),
               comment=None,
               existing_comment='Delivery channel used',
               existing_nullable=False)
        batch_op.alter_column('priority',
               existing_type=postgresql.ENUM('critical', 'important', 'optional', name='notificationprioritytype'),
               comment=None,
               existing_comment='Priority level at delivery',
               existing_nullable=False)
        batch_op.alter_column('notification_type',
               existing_type=postgresql.ENUM('stock_alert', 'diaper_change_reminder', 'expiry_warning', 'health_tip', 'system_update', 'marketing', name='notificationtypeenum'),
               comment=None,
               existing_comment='Type of notification delivered',
               existing_nullable=False)
        batch_op.alter_column('preferences_id',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='User preferences at time of delivery',
               existing_nullable=True)
        batch_op.alter_column('queue_item_id',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='Associated queue item ID',
               existing_nullable=True)
        batch_op.alter_column('user_id',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='Target user ID',
               existing_nullable=False)

    with op.batch_alter_table('inventory_items', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_inventory_items_size'))
        batch_op.drop_index(batch_op.f('ix_inventory_items_product_type'))
        batch_op.drop_index(batch_op.f('ix_inventory_items_child_id'))

    with op.batch_alter_table('growth_predictions', schema=None) as batch_op:
        batch_op.drop_table_comment(
        'growth_predictions',
        existing_comment='ML-based growth and size change predictions',
        schema=None
    )
        batch_op.drop_index(batch_op.f('ix_growth_predictions_child_id'))
        batch_op.create_unique_constraint('uq_growth_predictions_child', ['child_id'], postgresql_nulls_not_distinct=False)
        batch_op.alter_column('id',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='Unique identifier',
               existing_nullable=False)
        batch_op.alter_column('expires_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='When this prediction expires',
               existing_nullable=False)
        batch_op.alter_column('prediction_created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='When this prediction was created',
               existing_nullable=True)
        batch_op.alter_column('training_data_points',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Number of data points used for training',
               existing_nullable=True)
        batch_op.alter_column('model_version',
               existing_type=sa.VARCHAR(length=20),
               comment=None,
               existing_comment='ML model version used for prediction',
               existing_nullable=True)
        batch_op.alter_column('prediction_basis',
               existing_type=sa.TEXT(),
               comment=None,
               existing_comment='Data points and factors used for prediction',
               existing_nullable=True)
        batch_op.alter_column('next_size_recommendation',
               existing_type=sa.VARCHAR(length=10),
               comment=None,
               existing_comment='Recommended next size',
               existing_nullable=True)
        batch_op.alter_column('current_size',
               existing_type=sa.VARCHAR(length=10),
               comment=None,
               existing_comment='Current diaper size',
               existing_nullable=True)
        batch_op.alter_column('current_fit_efficiency',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment=None,
               existing_comment='Current diaper size fit efficiency percentage',
               existing_nullable=True)
        batch_op.alter_column('growth_velocity_cm_week',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment=None,
               existing_comment='Growth velocity in cm per week',
               existing_nullable=True)
        batch_op.alter_column('confidence_score',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment=None,
               existing_comment='Prediction confidence score (0-100)',
               existing_nullable=False)
        batch_op.alter_column('prediction_date_range',
               existing_type=sa.VARCHAR(length=50),
               comment=None,
               existing_comment="Predicted date range for size change (e.g., 'Jan 25-30')",
               existing_nullable=False)
        batch_op.alter_column('child_id',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='Child this prediction belongs to',
               existing_nullable=False)
        batch_op.drop_column('deleted_by')
        batch_op.drop_column('updated_by')
        batch_op.drop_column('created_by')
        batch_op.drop_column('is_deleted')
        batch_op.drop_column('deleted_at')
        batch_op.drop_column('updated_at')
        batch_op.drop_column('created_at')

    with op.batch_alter_table('consent_records', schema=None) as batch_op:
        batch_op.create_table_comment(
        'consent_records',
        'PIPEDA-compliant consent records with full audit trail',
        existing_comment=None,
        schema=None
    )
        batch_op.create_index('idx_consent_records_user_type', ['user_id', 'consent_type'], unique=False)
        batch_op.create_index('idx_consent_records_status', ['status'], unique=False)
        batch_op.create_index('idx_consent_records_granted_at', ['granted_at'], unique=False)
        batch_op.create_index('idx_consent_records_expires_at', ['expires_at'], unique=False)

    with op.batch_alter_table('consent_audit_logs', schema=None) as batch_op:
        batch_op.add_column(sa.Column('metadata', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True, comment='Additional metadata about the action'))
        batch_op.create_table_comment(
        'consent_audit_logs',
        'Comprehensive audit log for all consent-related activities',
        existing_comment=None,
        schema=None
    )
        batch_op.create_index('idx_consent_audit_logs_user_id_created', ['user_id', 'created_at'], unique=False)
        batch_op.create_index('idx_consent_audit_logs_consent_record', ['consent_record_id'], unique=False)
        batch_op.create_index('idx_consent_audit_logs_action', ['action'], unique=False)
        batch_op.drop_column('audit_metadata')

    with op.batch_alter_table('children', schema=None) as batch_op:
        batch_op.create_table_comment(
        'children',
        'Child profiles for diaper planning with Canadian privacy compliance',
        existing_comment=None,
        schema=None
    )
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.drop_index(batch_op.f('ix_children_family_id'))
        batch_op.create_index('idx_children_parent_id_active', ['parent_id'], unique=False, postgresql_where='(is_deleted = false)')
        batch_op.create_index('idx_children_onboarding', ['onboarding_completed'], unique=False)
        batch_op.create_index('idx_children_date_of_birth', ['date_of_birth'], unique=False)
        batch_op.create_index('idx_children_current_size', ['current_diaper_size'], unique=False)
        batch_op.alter_column('parent_id',
               existing_type=sa.UUID(),
               comment='Parent user ID',
               existing_comment='Parent user ID (legacy - deprecated in favor of family model)',
               existing_nullable=False)
        batch_op.drop_column('migrated_from_user')
        batch_op.drop_column('family_id')

    with op.batch_alter_table('analytics_weekly_patterns', schema=None) as batch_op:
        batch_op.drop_table_comment(
        'analytics_weekly_patterns',
        existing_comment='Weekly pattern cache for performance optimization',
        schema=None
    )
        batch_op.drop_index(batch_op.f('ix_analytics_weekly_patterns_week_start_date'))
        batch_op.drop_index(batch_op.f('ix_analytics_weekly_patterns_child_id'))
        batch_op.create_unique_constraint('uq_analytics_weekly_child_week', ['child_id', 'week_start_date'], postgresql_nulls_not_distinct=False)
        batch_op.alter_column('id',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='Unique identifier',
               existing_nullable=False)
        batch_op.alter_column('data_quality_score',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment=None,
               existing_comment='Data quality score (0-100)',
               existing_nullable=True)
        batch_op.alter_column('calculated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='When this pattern was calculated',
               existing_nullable=True)
        batch_op.alter_column('weekend_vs_weekday_ratio',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment=None,
               existing_comment='Weekend vs weekday usage ratio',
               existing_nullable=True)
        batch_op.alter_column('weekend_average',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment=None,
               existing_comment='Average changes per weekend day',
               existing_nullable=True)
        batch_op.alter_column('weekday_average',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment=None,
               existing_comment='Average changes per weekday',
               existing_nullable=True)
        batch_op.alter_column('hourly_distribution',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment=None,
               existing_comment='24-hour distribution data',
               existing_nullable=False)
        batch_op.alter_column('peak_hours',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment=None,
               existing_comment='Peak hours analysis {time_range: percentage}',
               existing_nullable=False)
        batch_op.alter_column('pattern_insights',
               existing_type=sa.TEXT(),
               comment=None,
               existing_comment='Human-readable pattern insights',
               existing_nullable=True)
        batch_op.alter_column('consistency_percentage',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment=None,
               existing_comment='Pattern consistency percentage (0-100)',
               existing_nullable=False)
        batch_op.alter_column('weekly_average',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment=None,
               existing_comment='Average changes per day for the week',
               existing_nullable=False)
        batch_op.alter_column('daily_counts',
               existing_type=postgresql.ARRAY(sa.INTEGER()),
               comment=None,
               existing_comment='Daily change counts [Mon, Tue, Wed, Thu, Fri, Sat, Sun]',
               existing_nullable=False)
        batch_op.alter_column('week_start_date',
               existing_type=sa.DATE(),
               comment=None,
               existing_comment='Start date of the week (Monday)',
               existing_nullable=False)
        batch_op.alter_column('child_id',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='Child this pattern belongs to',
               existing_nullable=False)
        batch_op.drop_column('deleted_by')
        batch_op.drop_column('updated_by')
        batch_op.drop_column('created_by')
        batch_op.drop_column('is_deleted')
        batch_op.drop_column('deleted_at')
        batch_op.drop_column('updated_at')
        batch_op.drop_column('created_at')

    with op.batch_alter_table('analytics_daily_summaries', schema=None) as batch_op:
        batch_op.drop_table_comment(
        'analytics_daily_summaries',
        existing_comment='Daily analytics summaries for performance optimization',
        schema=None
    )
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.create_foreign_key('analytics_daily_summaries_user_id_fkey', 'users', ['user_id'], ['id'], referent_schema='auth', ondelete='CASCADE')
        batch_op.drop_index(batch_op.f('ix_analytics_daily_summaries_user_id'))
        batch_op.drop_index(batch_op.f('ix_analytics_daily_summaries_date'))
        batch_op.drop_index(batch_op.f('ix_analytics_daily_summaries_child_id'))
        batch_op.create_unique_constraint('uq_analytics_daily_child_date', ['child_id', 'date'], postgresql_nulls_not_distinct=False)
        batch_op.alter_column('id',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='Unique identifier',
               existing_nullable=False)
        batch_op.alter_column('updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='When this summary was last updated',
               existing_nullable=True)
        batch_op.alter_column('created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='When this summary was created',
               existing_nullable=True)
        batch_op.alter_column('shortest_gap',
               existing_type=postgresql.INTERVAL(),
               comment=None,
               existing_comment='Shortest gap between changes',
               existing_nullable=True)
        batch_op.alter_column('longest_gap',
               existing_type=postgresql.INTERVAL(),
               comment=None,
               existing_comment='Longest gap between changes',
               existing_nullable=True)
        batch_op.alter_column('time_between_changes_avg',
               existing_type=postgresql.INTERVAL(),
               comment=None,
               existing_comment='Average time between diaper changes',
               existing_nullable=True)
        batch_op.alter_column('diaper_size',
               existing_type=sa.VARCHAR(length=10),
               comment=None,
               existing_comment='Primary diaper size used this day',
               existing_nullable=True)
        batch_op.alter_column('diaper_brand',
               existing_type=sa.VARCHAR(length=100),
               comment=None,
               existing_comment='Primary diaper brand used this day',
               existing_nullable=True)
        batch_op.alter_column('estimated_cost_cad',
               existing_type=sa.NUMERIC(precision=10, scale=2),
               comment=None,
               existing_comment='Estimated daily cost in CAD',
               existing_nullable=True)
        batch_op.alter_column('hourly_distribution',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment=None,
               existing_comment='Distribution of changes by hour {hour: count}',
               existing_nullable=False)
        batch_op.alter_column('change_times',
               existing_type=postgresql.ARRAY(postgresql.TIMESTAMP(timezone=True)),
               comment=None,
               existing_comment='Array of timestamps when changes occurred',
               existing_nullable=False)
        batch_op.alter_column('total_changes',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Total diaper changes for the day',
               existing_nullable=False)
        batch_op.alter_column('date',
               existing_type=sa.DATE(),
               comment=None,
               existing_comment='Date for this daily summary',
               existing_nullable=False)
        batch_op.alter_column('child_id',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='Child this summary belongs to',
               existing_nullable=False)
        batch_op.alter_column('user_id',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='User this summary belongs to',
               existing_nullable=False)
        batch_op.drop_column('deleted_by')
        batch_op.drop_column('updated_by')
        batch_op.drop_column('created_by')
        batch_op.drop_column('is_deleted')
        batch_op.drop_column('deleted_at')

    with op.batch_alter_table('analytics_cost_tracking', schema=None) as batch_op:
        batch_op.drop_table_comment(
        'analytics_cost_tracking',
        existing_comment='Monthly cost analysis and breakdown tracking',
        schema=None
    )
        batch_op.drop_index(batch_op.f('ix_analytics_cost_tracking_month_year'))
        batch_op.drop_index(batch_op.f('ix_analytics_cost_tracking_child_id'))
        batch_op.create_unique_constraint('uq_analytics_cost_child_month', ['child_id', 'month_year'], postgresql_nulls_not_distinct=False)
        batch_op.alter_column('id',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='Unique identifier',
               existing_nullable=False)
        batch_op.alter_column('calculated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               comment=None,
               existing_comment='When this cost analysis was calculated',
               existing_nullable=True)
        batch_op.alter_column('sizes_used',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment=None,
               existing_comment='Sizes used this month {size: count}',
               existing_nullable=True)
        batch_op.alter_column('brands_used',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               comment=None,
               existing_comment='Brands used this month {brand: count}',
               existing_nullable=True)
        batch_op.alter_column('primary_size',
               existing_type=sa.VARCHAR(length=10),
               comment=None,
               existing_comment='Most used diaper size this month',
               existing_nullable=True)
        batch_op.alter_column('primary_brand',
               existing_type=sa.VARCHAR(length=100),
               comment=None,
               existing_comment='Most used diaper brand this month',
               existing_nullable=True)
        batch_op.alter_column('cost_trend_7day',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment=None,
               existing_comment='7-day cost trend percentage',
               existing_nullable=True)
        batch_op.alter_column('most_expensive_day',
               existing_type=sa.VARCHAR(length=9),
               comment=None,
               existing_comment='Day of week with highest costs',
               existing_nullable=True)
        batch_op.alter_column('weekend_vs_weekday_usage',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment=None,
               existing_comment='Weekend vs weekday usage percentage',
               existing_nullable=True)
        batch_op.alter_column('efficiency_vs_target',
               existing_type=sa.NUMERIC(precision=5, scale=2),
               comment=None,
               existing_comment='Efficiency percentage vs target cost',
               existing_nullable=True)
        batch_op.alter_column('cost_per_change_cad',
               existing_type=sa.NUMERIC(precision=6, scale=4),
               comment=None,
               existing_comment='Average cost per diaper change in CAD',
               existing_nullable=False)
        batch_op.alter_column('total_cost_cad',
               existing_type=sa.NUMERIC(precision=10, scale=2),
               comment=None,
               existing_comment='Total monthly cost in CAD',
               existing_nullable=False)
        batch_op.alter_column('month_year',
               existing_type=sa.VARCHAR(length=7),
               comment=None,
               existing_comment='Month and year in format YYYY-MM',
               existing_nullable=False)
        batch_op.alter_column('child_id',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='Child this cost tracking belongs to',
               existing_nullable=False)
        batch_op.drop_column('deleted_by')
        batch_op.drop_column('updated_by')
        batch_op.drop_column('created_by')
        batch_op.drop_column('is_deleted')
        batch_op.drop_column('deleted_at')
        batch_op.drop_column('updated_at')
        batch_op.drop_column('created_at')

    op.create_table('objects',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('bucket_id', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('name', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('owner', sa.UUID(), autoincrement=False, nullable=True, comment='Field is deprecated, use owner_id instead'),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('last_accessed_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('metadata', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('path_tokens', postgresql.ARRAY(sa.TEXT()), sa.Computed("string_to_array(name, '/'::text)", persisted=True), autoincrement=False, nullable=True),
    sa.Column('version', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('owner_id', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('user_metadata', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['bucket_id'], ['storage.buckets.id'], name='objects_bucketId_fkey'),
    sa.PrimaryKeyConstraint('id', name='objects_pkey'),
    schema='storage'
    )
    with op.batch_alter_table('objects', schema='storage') as batch_op:
        batch_op.create_index('name_prefix_search', ['name'], unique=False, postgresql_ops={'name': 'text_pattern_ops'})
        batch_op.create_index('idx_objects_bucket_id_name', ['bucket_id', 'name'], unique=False)
        batch_op.create_index('bucketid_objname', ['bucket_id', 'name'], unique=False)

    op.create_table('instances',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('uuid', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('raw_base_config', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name='instances_pkey'),
    schema='auth',
    comment='Auth: Manages users across multiple sites.'
    )
    op.create_table('oauth_clients',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('client_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('client_secret_hash', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('registration_type', postgresql.ENUM('dynamic', 'manual', name='oauth_registration_type', schema='auth'), autoincrement=False, nullable=False),
    sa.Column('redirect_uris', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('grant_types', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('client_name', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('client_uri', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('logo_uri', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('deleted_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.CheckConstraint('char_length(client_name) <= 1024', name='oauth_clients_client_name_length'),
    sa.CheckConstraint('char_length(client_uri) <= 2048', name='oauth_clients_client_uri_length'),
    sa.CheckConstraint('char_length(logo_uri) <= 2048', name='oauth_clients_logo_uri_length'),
    sa.PrimaryKeyConstraint('id', name='oauth_clients_pkey'),
    sa.UniqueConstraint('client_id', name='oauth_clients_client_id_key', postgresql_include=[], postgresql_nulls_not_distinct=False),
    schema='auth'
    )
    with op.batch_alter_table('oauth_clients', schema='auth') as batch_op:
        batch_op.create_index('oauth_clients_deleted_at_idx', ['deleted_at'], unique=False)
        batch_op.create_index('oauth_clients_client_id_idx', ['client_id'], unique=False)

    op.create_table('refresh_tokens',
    sa.Column('instance_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('id', sa.BIGINT(), server_default=sa.text("nextval('auth.refresh_tokens_id_seq'::regclass)"), autoincrement=True, nullable=False),
    sa.Column('token', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('user_id', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('revoked', sa.BOOLEAN(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('parent', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('session_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['session_id'], ['auth.sessions.id'], name='refresh_tokens_session_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='refresh_tokens_pkey'),
    sa.UniqueConstraint('token', name='refresh_tokens_token_unique', postgresql_include=[], postgresql_nulls_not_distinct=False),
    schema='auth',
    comment='Auth: Store of tokens used to refresh JWT tokens once they expire.'
    )
    with op.batch_alter_table('refresh_tokens', schema='auth') as batch_op:
        batch_op.create_index('refresh_tokens_updated_at_idx', [sa.text('updated_at DESC')], unique=False)
        batch_op.create_index('refresh_tokens_session_id_revoked_idx', ['session_id', 'revoked'], unique=False)
        batch_op.create_index('refresh_tokens_parent_idx', ['parent'], unique=False)
        batch_op.create_index('refresh_tokens_instance_id_user_id_idx', ['instance_id', 'user_id'], unique=False)
        batch_op.create_index('refresh_tokens_instance_id_idx', ['instance_id'], unique=False)

    op.create_table('sso_providers',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('resource_id', sa.TEXT(), autoincrement=False, nullable=True, comment='Auth: Uniquely identifies a SSO provider according to a user-chosen resource ID (case insensitive), useful in infrastructure as code.'),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('disabled', sa.BOOLEAN(), autoincrement=False, nullable=True),
    sa.CheckConstraint('resource_id = NULL::text OR char_length(resource_id) > 0', name='resource_id not empty'),
    sa.PrimaryKeyConstraint('id', name='sso_providers_pkey'),
    schema='auth',
    comment='Auth: Manages SSO identity provider information; see saml_providers for SAML.',
    postgresql_ignore_search_path=False
    )
    with op.batch_alter_table('sso_providers', schema='auth') as batch_op:
        batch_op.create_index('sso_providers_resource_id_pattern_idx', ['resource_id'], unique=False, postgresql_ops={'resource_id': 'text_pattern_ops'})
        batch_op.create_index('sso_providers_resource_id_idx', [sa.text('lower(resource_id)')], unique=False)

    op.create_table('mfa_challenges',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('factor_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=False),
    sa.Column('verified_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('ip_address', postgresql.INET(), autoincrement=False, nullable=False),
    sa.Column('otp_code', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('web_authn_session_data', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['factor_id'], ['auth.mfa_factors.id'], name='mfa_challenges_auth_factor_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='mfa_challenges_pkey'),
    schema='auth',
    comment='auth: stores metadata about challenge requests made'
    )
    with op.batch_alter_table('mfa_challenges', schema='auth') as batch_op:
        batch_op.create_index('mfa_challenge_created_at_idx', [sa.text('created_at DESC')], unique=False)

    op.create_table('subscription',
    sa.Column('id', sa.BIGINT(), sa.Identity(always=True, start=1, increment=1, minvalue=1, maxvalue=9223372036854775807, cycle=False, cache=1), autoincrement=True, nullable=False),
    sa.Column('subscription_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('entity', postgresql.REGCLASS(), autoincrement=False, nullable=False),
    sa.Column('filters', sa.NullType(), server_default=sa.text("'{}'::realtime.user_defined_filter[]"), autoincrement=False, nullable=False),
    sa.Column('claims', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('claims_role', sa.NullType(), sa.Computed("realtime.to_regrole((claims ->> 'role'::text))", persisted=True), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text("timezone('utc'::text, now())"), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name='pk_subscription'),
    schema='realtime'
    )
    with op.batch_alter_table('subscription', schema='realtime') as batch_op:
        batch_op.create_index('subscription_subscription_id_entity_filters_key', ['subscription_id', 'entity', 'filters'], unique=False)
        batch_op.create_index('ix_realtime_subscription_entity', ['entity'], unique=False)

    op.create_table('buckets',
    sa.Column('id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('name', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('owner', sa.UUID(), autoincrement=False, nullable=True, comment='Field is deprecated, use owner_id instead'),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('public', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=True),
    sa.Column('avif_autodetection', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=True),
    sa.Column('file_size_limit', sa.BIGINT(), autoincrement=False, nullable=True),
    sa.Column('allowed_mime_types', postgresql.ARRAY(sa.TEXT()), autoincrement=False, nullable=True),
    sa.Column('owner_id', sa.TEXT(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name='buckets_pkey'),
    schema='storage',
    postgresql_ignore_search_path=False
    )
    with op.batch_alter_table('buckets', schema='storage') as batch_op:
        batch_op.create_index('bname', ['name'], unique=False)

    op.create_table('flow_state',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('auth_code', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('code_challenge_method', postgresql.ENUM('s256', 'plain', name='code_challenge_method', schema='auth'), autoincrement=False, nullable=False),
    sa.Column('code_challenge', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('provider_type', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('provider_access_token', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('provider_refresh_token', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('authentication_method', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('auth_code_issued_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name='flow_state_pkey'),
    schema='auth',
    comment='stores metadata for pkce logins',
    postgresql_ignore_search_path=False
    )
    with op.batch_alter_table('flow_state', schema='auth') as batch_op:
        batch_op.create_index('idx_user_id_auth_method', ['user_id', 'authentication_method'], unique=False)
        batch_op.create_index('idx_auth_code', ['auth_code'], unique=False)
        batch_op.create_index('flow_state_created_at_idx', [sa.text('created_at DESC')], unique=False)

    op.create_table('sessions',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('factor_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('aal', postgresql.ENUM('aal1', 'aal2', 'aal3', name='aal_level', schema='auth'), autoincrement=False, nullable=True),
    sa.Column('not_after', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True, comment='Auth: Not after is a nullable column that contains a timestamp after which the session should be regarded as expired.'),
    sa.Column('refreshed_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('user_agent', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('ip', postgresql.INET(), autoincrement=False, nullable=True),
    sa.Column('tag', sa.TEXT(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['auth.users.id'], name='sessions_user_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='sessions_pkey'),
    schema='auth',
    comment='Auth: Stores session data associated to a user.',
    postgresql_ignore_search_path=False
    )
    with op.batch_alter_table('sessions', schema='auth') as batch_op:
        batch_op.create_index('user_id_created_at_idx', ['user_id', 'created_at'], unique=False)
        batch_op.create_index('sessions_user_id_idx', ['user_id'], unique=False)
        batch_op.create_index('sessions_not_after_idx', [sa.text('not_after DESC')], unique=False)

    op.create_table('one_time_tokens',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('token_type', postgresql.ENUM('confirmation_token', 'reauthentication_token', 'recovery_token', 'email_change_token_new', 'email_change_token_current', 'phone_change_token', name='one_time_token_type', schema='auth'), autoincrement=False, nullable=False),
    sa.Column('token_hash', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('relates_to', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.CheckConstraint('char_length(token_hash) > 0', name='one_time_tokens_token_hash_check'),
    sa.ForeignKeyConstraint(['user_id'], ['auth.users.id'], name='one_time_tokens_user_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='one_time_tokens_pkey'),
    schema='auth'
    )
    with op.batch_alter_table('one_time_tokens', schema='auth') as batch_op:
        batch_op.create_index('one_time_tokens_user_id_token_type_key', ['user_id', 'token_type'], unique=False)
        batch_op.create_index('one_time_tokens_token_hash_hash_idx', ['token_hash'], unique=False, postgresql_using='hash')
        batch_op.create_index('one_time_tokens_relates_to_hash_idx', ['relates_to'], unique=False, postgresql_using='hash')

    op.create_table('migrations',
    sa.Column('id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('name', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('hash', sa.VARCHAR(length=40), autoincrement=False, nullable=False),
    sa.Column('executed_at', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name='migrations_pkey'),
    sa.UniqueConstraint('name', name='migrations_name_key', postgresql_include=[], postgresql_nulls_not_distinct=False),
    schema='storage'
    )
    op.create_table('sso_domains',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('sso_provider_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('domain', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.CheckConstraint('char_length(domain) > 0', name='domain not empty'),
    sa.ForeignKeyConstraint(['sso_provider_id'], ['auth.sso_providers.id'], name='sso_domains_sso_provider_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='sso_domains_pkey'),
    schema='auth',
    comment='Auth: Manages SSO email address domain mapping to an SSO Identity Provider.'
    )
    with op.batch_alter_table('sso_domains', schema='auth') as batch_op:
        batch_op.create_index('sso_domains_sso_provider_id_idx', ['sso_provider_id'], unique=False)
        batch_op.create_index('sso_domains_domain_idx', [sa.text('lower(domain)')], unique=False)

    op.create_table('saml_relay_states',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('sso_provider_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('request_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('for_email', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('redirect_to', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('flow_state_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.CheckConstraint('char_length(request_id) > 0', name='request_id not empty'),
    sa.ForeignKeyConstraint(['flow_state_id'], ['auth.flow_state.id'], name='saml_relay_states_flow_state_id_fkey', ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['sso_provider_id'], ['auth.sso_providers.id'], name='saml_relay_states_sso_provider_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='saml_relay_states_pkey'),
    schema='auth',
    comment='Auth: Contains SAML Relay State information for each Service Provider initiated login.'
    )
    with op.batch_alter_table('saml_relay_states', schema='auth') as batch_op:
        batch_op.create_index('saml_relay_states_sso_provider_id_idx', ['sso_provider_id'], unique=False)
        batch_op.create_index('saml_relay_states_for_email_idx', ['for_email'], unique=False)
        batch_op.create_index('saml_relay_states_created_at_idx', [sa.text('created_at DESC')], unique=False)

    op.create_table('s3_multipart_uploads',
    sa.Column('id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('in_progress_size', sa.BIGINT(), server_default=sa.text('0'), autoincrement=False, nullable=False),
    sa.Column('upload_signature', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('bucket_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('key', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('version', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('owner_id', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('user_metadata', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['bucket_id'], ['storage.buckets.id'], name='s3_multipart_uploads_bucket_id_fkey'),
    sa.PrimaryKeyConstraint('id', name='s3_multipart_uploads_pkey'),
    schema='storage',
    postgresql_ignore_search_path=False
    )
    with op.batch_alter_table('s3_multipart_uploads', schema='storage') as batch_op:
        batch_op.create_index('idx_multipart_uploads_list', ['bucket_id', 'key', 'created_at'], unique=False)

    op.create_table('audit_log_entries',
    sa.Column('instance_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('payload', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('ip_address', sa.VARCHAR(length=64), server_default=sa.text("''::character varying"), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name='audit_log_entries_pkey'),
    schema='auth',
    comment='Auth: Audit trail for user actions.'
    )
    with op.batch_alter_table('audit_log_entries', schema='auth') as batch_op:
        batch_op.create_index('audit_logs_instance_id_idx', ['instance_id'], unique=False)

    op.create_table('secrets',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('name', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('description', sa.TEXT(), server_default=sa.text("''::text"), autoincrement=False, nullable=False),
    sa.Column('secret', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('key_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('nonce', postgresql.BYTEA(), server_default=sa.text('vault._crypto_aead_det_noncegen()'), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name='secrets_pkey'),
    schema='vault',
    comment='Table with encrypted `secret` column for storing sensitive information on disk.'
    )
    with op.batch_alter_table('secrets', schema='vault') as batch_op:
        batch_op.create_index('secrets_name_idx', ['name'], unique=False, postgresql_where='(name IS NOT NULL)')

    op.create_table('saml_providers',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('sso_provider_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('entity_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('metadata_xml', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('metadata_url', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('attribute_mapping', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('name_id_format', sa.TEXT(), autoincrement=False, nullable=True),
    sa.CheckConstraint('char_length(entity_id) > 0', name='entity_id not empty'),
    sa.CheckConstraint('char_length(metadata_xml) > 0', name='metadata_xml not empty'),
    sa.CheckConstraint('metadata_url = NULL::text OR char_length(metadata_url) > 0', name='metadata_url not empty'),
    sa.ForeignKeyConstraint(['sso_provider_id'], ['auth.sso_providers.id'], name='saml_providers_sso_provider_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='saml_providers_pkey'),
    sa.UniqueConstraint('entity_id', name='saml_providers_entity_id_key', postgresql_include=[], postgresql_nulls_not_distinct=False),
    schema='auth',
    comment='Auth: Manages SAML Identity Provider connections.'
    )
    with op.batch_alter_table('saml_providers', schema='auth') as batch_op:
        batch_op.create_index('saml_providers_sso_provider_id_idx', ['sso_provider_id'], unique=False)

    op.create_table('schema_migrations',
    sa.Column('version', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('version', name='schema_migrations_pkey'),
    schema='auth',
    comment='Auth: Manages updates to the auth system.'
    )
    op.create_table('messages',
    sa.Column('topic', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('extension', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('payload', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('event', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('private', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('inserted_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', 'inserted_at', name='messages_pkey'),
    schema='realtime'
    )
    op.create_table('users',
    sa.Column('instance_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('aud', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('role', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('email', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('encrypted_password', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('email_confirmed_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('invited_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('confirmation_token', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('confirmation_sent_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('recovery_token', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('recovery_sent_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('email_change_token_new', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('email_change', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('email_change_sent_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('last_sign_in_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('raw_app_meta_data', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('raw_user_meta_data', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('is_super_admin', sa.BOOLEAN(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('phone', sa.TEXT(), server_default=sa.text('NULL::character varying'), autoincrement=False, nullable=True),
    sa.Column('phone_confirmed_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('phone_change', sa.TEXT(), server_default=sa.text("''::character varying"), autoincrement=False, nullable=True),
    sa.Column('phone_change_token', sa.VARCHAR(length=255), server_default=sa.text("''::character varying"), autoincrement=False, nullable=True),
    sa.Column('phone_change_sent_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('confirmed_at', postgresql.TIMESTAMP(timezone=True), sa.Computed('LEAST(email_confirmed_at, phone_confirmed_at)', persisted=True), autoincrement=False, nullable=True),
    sa.Column('email_change_token_current', sa.VARCHAR(length=255), server_default=sa.text("''::character varying"), autoincrement=False, nullable=True),
    sa.Column('email_change_confirm_status', sa.SMALLINT(), server_default=sa.text('0'), autoincrement=False, nullable=True),
    sa.Column('banned_until', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('reauthentication_token', sa.VARCHAR(length=255), server_default=sa.text("''::character varying"), autoincrement=False, nullable=True),
    sa.Column('reauthentication_sent_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('is_sso_user', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=False, comment='Auth: Set this column to true when the account comes from SSO. These accounts can have duplicate emails.'),
    sa.Column('deleted_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('is_anonymous', sa.BOOLEAN(), server_default=sa.text('false'), autoincrement=False, nullable=False),
    sa.CheckConstraint('email_change_confirm_status >= 0 AND email_change_confirm_status <= 2', name='users_email_change_confirm_status_check'),
    sa.PrimaryKeyConstraint('id', name='users_pkey'),
    sa.UniqueConstraint('phone', name='users_phone_key', postgresql_include=[], postgresql_nulls_not_distinct=False),
    schema='auth',
    comment='Auth: Stores user login data within a secure schema.',
    postgresql_ignore_search_path=False
    )
    with op.batch_alter_table('users', schema='auth') as batch_op:
        batch_op.create_index('users_is_anonymous_idx', ['is_anonymous'], unique=False)
        batch_op.create_index('users_instance_id_idx', ['instance_id'], unique=False)
        batch_op.create_index('users_instance_id_email_idx', ['instance_id', sa.text('lower(email::text)')], unique=False)
        batch_op.create_index('users_email_partial_key', ['email'], unique=False, postgresql_where='(is_sso_user = false)')
        batch_op.create_index('recovery_token_idx', ['recovery_token'], unique=False, postgresql_where="((recovery_token)::text !~ '^[0-9 ]*$'::text)")
        batch_op.create_index('reauthentication_token_idx', ['reauthentication_token'], unique=False, postgresql_where="((reauthentication_token)::text !~ '^[0-9 ]*$'::text)")
        batch_op.create_index('email_change_token_new_idx', ['email_change_token_new'], unique=False, postgresql_where="((email_change_token_new)::text !~ '^[0-9 ]*$'::text)")
        batch_op.create_index('email_change_token_current_idx', ['email_change_token_current'], unique=False, postgresql_where="((email_change_token_current)::text !~ '^[0-9 ]*$'::text)")
        batch_op.create_index('confirmation_token_idx', ['confirmation_token'], unique=False, postgresql_where="((confirmation_token)::text !~ '^[0-9 ]*$'::text)")

    op.create_table('mfa_factors',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('friendly_name', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('factor_type', postgresql.ENUM('totp', 'webauthn', 'phone', name='factor_type', schema='auth'), autoincrement=False, nullable=False),
    sa.Column('status', postgresql.ENUM('unverified', 'verified', name='factor_status', schema='auth'), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=False),
    sa.Column('secret', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('phone', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('last_challenged_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('web_authn_credential', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('web_authn_aaguid', sa.UUID(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['auth.users.id'], name='mfa_factors_user_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='mfa_factors_pkey'),
    sa.UniqueConstraint('last_challenged_at', name='mfa_factors_last_challenged_at_key', postgresql_include=[], postgresql_nulls_not_distinct=False),
    schema='auth',
    comment='auth: stores metadata about factors'
    )
    with op.batch_alter_table('mfa_factors', schema='auth') as batch_op:
        batch_op.create_index('unique_phone_factor_per_user', ['user_id', 'phone'], unique=False)
        batch_op.create_index('mfa_factors_user_id_idx', ['user_id'], unique=False)
        batch_op.create_index('mfa_factors_user_friendly_name_unique', ['friendly_name', 'user_id'], unique=False, postgresql_where="(TRIM(BOTH FROM friendly_name) <> ''::text)")
        batch_op.create_index('factor_id_created_at_idx', ['user_id', 'created_at'], unique=False)

    op.create_table('identities',
    sa.Column('provider_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('identity_data', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('provider', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('last_sign_in_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('email', sa.TEXT(), sa.Computed("lower((identity_data ->> 'email'::text))", persisted=True), autoincrement=False, nullable=True, comment='Auth: Email is a generated column that references the optional email property in the identity_data'),
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['user_id'], ['auth.users.id'], name='identities_user_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='identities_pkey'),
    sa.UniqueConstraint('provider_id', 'provider', name='identities_provider_id_provider_unique', postgresql_include=[], postgresql_nulls_not_distinct=False),
    schema='auth',
    comment='Auth: Stores identities associated to a user.'
    )
    with op.batch_alter_table('identities', schema='auth') as batch_op:
        batch_op.create_index('identities_user_id_idx', ['user_id'], unique=False)
        batch_op.create_index('identities_email_idx', ['email'], unique=False, postgresql_ops={'email': 'text_pattern_ops'})

    op.create_table('s3_multipart_uploads_parts',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), autoincrement=False, nullable=False),
    sa.Column('upload_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('size', sa.BIGINT(), server_default=sa.text('0'), autoincrement=False, nullable=False),
    sa.Column('part_number', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('bucket_id', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('key', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('etag', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('owner_id', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('version', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['bucket_id'], ['storage.buckets.id'], name='s3_multipart_uploads_parts_bucket_id_fkey'),
    sa.ForeignKeyConstraint(['upload_id'], ['storage.s3_multipart_uploads.id'], name='s3_multipart_uploads_parts_upload_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='s3_multipart_uploads_parts_pkey'),
    schema='storage'
    )
    op.create_table('schema_migrations',
    sa.Column('version', sa.BIGINT(), autoincrement=False, nullable=False),
    sa.Column('inserted_at', postgresql.TIMESTAMP(precision=0), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('version', name='schema_migrations_pkey'),
    schema='realtime'
    )
    op.create_table('mfa_amr_claims',
    sa.Column('session_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=False),
    sa.Column('authentication_method', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['session_id'], ['auth.sessions.id'], name='mfa_amr_claims_session_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='amr_id_pk'),
    sa.UniqueConstraint('session_id', 'authentication_method', name='mfa_amr_claims_session_id_authentication_method_pkey', postgresql_include=[], postgresql_nulls_not_distinct=False),
    schema='auth',
    comment='auth: stores authenticator method reference claims for multi factor authentication'
    )
    with op.batch_alter_table('family_child_access', schema=None) as batch_op:
        batch_op.drop_index('idx_family_child_family')
        batch_op.drop_index('idx_family_child_child')

    op.drop_table('family_child_access')
    with op.batch_alter_table('caregiver_presence', schema=None) as batch_op:
        batch_op.drop_index('idx_presence_status')
        batch_op.drop_index('idx_presence_last_seen')
        batch_op.drop_index('idx_presence_family')
        batch_op.drop_index('idx_presence_child')

    op.drop_table('caregiver_presence')
    with op.batch_alter_table('activities', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_activities_logged_by_user_id'))
        batch_op.drop_index(batch_op.f('ix_activities_logged_at'))
        batch_op.drop_index(batch_op.f('ix_activities_child_id'))
        batch_op.drop_index(batch_op.f('ix_activities_activity_type'))

    op.drop_table('activities')
    with op.batch_alter_table('family_members', schema=None) as batch_op:
        batch_op.drop_index('idx_family_members_user')
        batch_op.drop_index('idx_family_members_status')
        batch_op.drop_index('idx_family_members_role')
        batch_op.drop_index('idx_family_members_family')

    op.drop_table('family_members')
    with op.batch_alter_table('collaboration_logs', schema=None) as batch_op:
        batch_op.drop_index('idx_logs_family')
        batch_op.drop_index('idx_logs_created')
        batch_op.drop_index('idx_logs_actor')
        batch_op.drop_index('idx_logs_action')

    op.drop_table('collaboration_logs')
    with op.batch_alter_table('caregiver_invitations', schema=None) as batch_op:
        batch_op.drop_index('idx_invitations_token')
        batch_op.drop_index('idx_invitations_status')
        batch_op.drop_index('idx_invitations_family')
        batch_op.drop_index('idx_invitations_email')

    op.drop_table('caregiver_invitations')
    with op.batch_alter_table('families', schema=None) as batch_op:
        batch_op.drop_index('idx_families_type')
        batch_op.drop_index('idx_families_created_by')

    op.drop_table('families')
    # ### end Alembic commands ###